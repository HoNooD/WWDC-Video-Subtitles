
1
00:00:07,140 --> 00:00:16,283
(音楽)

2
00:00:20,988 --> 00:00:22,289
(拍手)

3
00:00:22,389 --> 00:00:23,390
こんにちは

4
00:00:25,259 --> 00:00:29,162
Turi Createの
セッションへようこそ

5
00:00:30,197 --> 00:00:33,901
今回の土台である
Create MLのセッションでは

6
00:00:34,001 --> 00:00:37,538
Swiftによる機械学習について
説明しました

7
00:00:37,638 --> 00:00:41,241
見逃した方は
後でご覧になってください

8
00:00:42,409 --> 00:00:48,582
Turi Createで実現できるのは
インテリジェントなユーザ体験です

9
00:00:49,716 --> 00:00:53,387
例えば 朝食の写真の
食べ物をタップし

10
00:00:53,487 --> 00:00:57,724
カロリーを
表示させることもできます

11
00:00:59,326 --> 00:01:04,897
iPhoneを使った単純な動作で
照明の制御も可能です

12
00:00:59,326 --> 00:01:04,897
iPhoneを使った単純な動作で
照明の制御も可能です

13
00:01:07,568 --> 00:01:10,270
リアルタイムで
物体の追跡も可能

14
00:01:10,370 --> 00:01:14,341
犬とか 身近にいなければ
犬の写真とか

15
00:01:14,541 --> 00:01:16,710
(笑い声)

16
00:01:17,678 --> 00:01:21,515
ゲームで使う
カスタムアバターでは

17
00:01:21,615 --> 00:01:27,154
ユーザが選んだヒゲに合わせて
髪型を薦めることもできます

18
00:01:28,455 --> 00:01:34,261
写真に芸術的なフィルタを
かけることも可能です

19
00:01:35,596 --> 00:01:38,065
これらのユーザ体験には―

20
00:01:38,165 --> 00:01:40,501
いくつか共通点があります

21
00:01:40,968 --> 00:01:43,904
どれも機械学習を使っており

22
00:01:44,738 --> 00:01:48,408
ほんの少しのデータで
実行可能

23
00:01:49,943 --> 00:01:52,446
どのモデルも
Turi Createで作り

24
00:01:52,546 --> 00:01:54,748
Core MLでデプロイ

25
00:01:55,883 --> 00:02:00,621
今日は これらに使う
５段階のレシピを説明します

26
00:01:55,883 --> 00:02:00,621
今日は これらに使う
５段階のレシピを説明します

27
00:02:01,688 --> 00:02:05,759
デモは全部
ラボでご覧いただけます

28
00:02:05,859 --> 00:02:09,729
ぜひ実際に
試してみてください

29
00:02:11,932 --> 00:02:14,268
Turi Createは
Pythonのパッケージで

30
00:02:14,368 --> 00:02:16,670
Core MLモデルを
作成できます

31
00:02:17,371 --> 00:02:18,872
使い方は簡単

32
00:02:18,972 --> 00:02:22,476
機械学習に
特別詳しくなくても

33
00:02:22,576 --> 00:02:25,145
こうしたユーザ体験を
生み出せます

34
00:02:25,546 --> 00:02:28,982
タスクにフォーカスし
使いやすくしました

35
00:02:29,116 --> 00:02:33,587
複雑な機械学習アルゴリズムを
省いて

36
00:02:33,687 --> 00:02:37,090
ユーザ体験に
フォーカスできるのです

37
00:02:37,991 --> 00:02:42,596
Turi Createは
クロスプラットフォームで

38
00:02:42,996 --> 00:02:44,798
オープンソースです

39
00:02:45,666 --> 00:02:50,637
GitHubにレポジトリが
あるのでご覧ください

40
00:02:51,371 --> 00:02:54,741
皆さんと一緒に
Turi Createを

41
00:02:54,842 --> 00:02:57,544
よりよくしたいと
思っています

42
00:02:58,879 --> 00:03:04,551
今回 Turi Create 5.0の
ベータ版をリリースしました

43
00:02:58,879 --> 00:03:04,551
今回 Turi Create 5.0の
ベータ版をリリースしました

44
00:03:04,852 --> 00:03:08,422
GPUアクセラレーションなどの
新機能について―

45
00:03:08,522 --> 00:03:11,758
後で詳しく説明します

46
00:03:13,293 --> 00:03:16,530
今日の本題は
Core MLモデル作成の

47
00:03:16,630 --> 00:03:18,799
５段階のレシピです

48
00:03:19,066 --> 00:03:21,935
まずは各段階を説明してから

49
00:03:22,035 --> 00:03:24,805
デモとコードを
ご覧に入れます

50
00:03:26,540 --> 00:03:31,345
第１段階はタスクを理解し
機械学習での―

51
00:03:31,445 --> 00:03:34,815
タスクの参照の仕方を
理解すること

52
00:03:35,816 --> 00:03:39,353
第２段階は
タスクに必要なデータの

53
00:03:39,453 --> 00:03:42,222
種類と量を把握すること

54
00:03:43,957 --> 00:03:46,460
第３段階はモデルの作成

55
00:03:48,262 --> 00:03:51,765
第４段階では
モデルの評価を行い

56
00:03:51,865 --> 00:03:55,235
その質や
作成が可能かを判断します

57
00:03:56,370 --> 00:04:01,175
第５段階ではCore MLを使い
デプロイします

58
00:03:56,370 --> 00:04:01,175
第５段階ではCore MLを使い
デプロイします

59
00:04:02,242 --> 00:04:05,112
詳しく説明していきますね

60
00:04:05,979 --> 00:04:10,684
Turi Createは機械学習の
様々なタスクを達成でき

61
00:04:10,784 --> 00:04:13,654
多種類のデータに
対応できます

62
00:04:13,854 --> 00:04:16,390
例えば お持ちの画像に

63
00:04:16,490 --> 00:04:20,093
画像分類や物体検知を
行うことができます

64
00:04:20,726 --> 00:04:24,198
パーソナライズドレコメンドも可能

65
00:04:24,865 --> 00:04:30,604
歩行や挙手 跳躍などの動きを
自動的に検出できますし

66
00:04:31,738 --> 00:04:35,843
テキストから
ユーザの気持ちを理解できます

67
00:04:36,143 --> 00:04:39,913
分類や回帰など
従来の機械学習アルゴリズムを

68
00:04:40,013 --> 00:04:42,649
使うことも可能です

69
00:04:44,818 --> 00:04:49,423
初心者の方は
混乱されたかもしれませんね

70
00:04:49,523 --> 00:04:54,161
簡単な表にまとめたものが
こちらです

71
00:04:54,294 --> 00:04:58,465
タスクの種類と
機械学習の用語を

72
00:04:58,565 --> 00:05:01,468
分かりやすく並べてみました

73
00:04:58,565 --> 00:05:01,468
分かりやすく並べてみました

74
00:05:01,568 --> 00:05:06,740
最初にお話しした
インテリジェントなユーザ体験に

75
00:05:06,840 --> 00:05:09,309
タスクを当てはめてみます

76
00:05:09,543 --> 00:05:14,014
例えば 写真の花の種類を
識別することを

77
00:05:14,114 --> 00:05:16,149
画像分類といいます

78
00:05:17,384 --> 00:05:22,890
朝食の写真に写るそれぞれの
食べ物を認識するのは

79
00:05:22,990 --> 00:05:25,192
物体検知です

80
00:05:26,393 --> 00:05:29,930
写真に芸術的な
エフェクトをかけるのは

81
00:05:30,030 --> 00:05:31,899
スタイル変換です

82
00:05:33,867 --> 00:05:39,806
デバイスに搭載されたセンサーで
動きを認識するのは

83
00:05:39,907 --> 00:05:42,176
“アクティビティ分類”

84
00:05:44,211 --> 00:05:47,814
パーソナライズドレコメンドの
ことは

85
00:05:47,915 --> 00:05:50,417
レコメンダシステムといいます

86
00:05:52,653 --> 00:05:56,590
すばらしいことに
この５段階のレシピは

87
00:05:56,690 --> 00:05:58,458
コードにも使えます

88
00:05:59,059 --> 00:06:01,495
まずTuri Createを
インポート

89
00:05:59,059 --> 00:06:01,495
まずTuri Createを
インポート

90
00:06:02,396 --> 00:06:06,633
SFrameというデータ構造で
データをロード

91
00:06:06,733 --> 00:06:10,337
SFrameについては
後ほど説明します

92
00:06:11,538 --> 00:06:15,742
関数“.create”を
使ってモデルを作成

93
00:06:15,843 --> 00:06:20,814
この関数は複雑な機械学習を
省いてくれます

94
00:06:22,850 --> 00:06:27,387
次に関数“.evaluate”で
モデルを評価します

95
00:06:28,789 --> 00:06:31,358
最後に モデルを
エクスポートします

96
00:06:31,458 --> 00:06:33,460
mlmodel形式にした後

97
00:06:33,560 --> 00:06:36,964
Xcodeに
ドラッグ＆ドロップ

98
00:06:37,598 --> 00:06:42,336
このレシピはTuri Createの
どのタスクにも

99
00:06:42,436 --> 00:06:44,004
使えると話しました

100
00:06:44,137 --> 00:06:46,073
物体検知でも

101
00:06:46,740 --> 00:06:48,442
画像分類でも

102
00:06:49,042 --> 00:06:53,280
アクティビティ分類でも
やり方は同じです

103
00:06:55,349 --> 00:06:56,850
最初のデモは―

104
00:06:56,950 --> 00:06:59,219
カロリー計算の
アプリケーションです

105
00:06:59,319 --> 00:07:01,522
物体検知モデルを
使っています

106
00:06:59,319 --> 00:07:01,522
物体検知モデルを
使っています

107
00:07:01,622 --> 00:07:05,959
画像の食べ物ごとに
位置を認識させて

108
00:07:06,059 --> 00:07:10,497
タップしたらカロリーが
表示されるようにします

109
00:07:13,467 --> 00:07:18,172
機械学習モデルの作成に
必要なデータは何か？

110
00:07:19,573 --> 00:07:20,707
まずは画像です

111
00:07:20,807 --> 00:07:24,077
単純な画像分類を
行うだけなら

112
00:07:24,178 --> 00:07:28,715
画像一式と各画像の
ラベルがあれば十分です

113
00:07:29,249 --> 00:07:33,720
物体検知には
それでは足りません

114
00:07:33,820 --> 00:07:38,125
画像の内容と物体の位置の
理解が必要です

115
00:07:38,859 --> 00:07:44,097
こちらの画像には
コーヒーの周りに赤い枠があります

116
00:07:44,498 --> 00:07:46,833
クロワッサンには
緑の枠です

117
00:07:47,201 --> 00:07:52,072
これは境界ボックスといい
JSON形式で表示されます

118
00:07:52,172 --> 00:07:56,376
ラベル 高さと幅
xとyの座標を使います

119
00:07:56,543 --> 00:08:00,247
xとyは境界ボックスの
中心を参照します

120
00:07:56,543 --> 00:08:00,247
xとyは境界ボックスの
中心を参照します

121
00:08:00,414 --> 00:08:05,986
物体検知では
画像上の複数の物体を参照し

122
00:08:06,086 --> 00:08:08,322
検知できるのです

123
00:08:10,157 --> 00:08:14,995
この例では
SFrameにデータをロードすると

124
00:08:15,295 --> 00:08:17,931
カラムが２つできます

125
00:08:18,031 --> 00:08:20,234
１つは画像のカラム

126
00:08:20,367 --> 00:08:24,838
もう１つはJSON形式の
アノテーションです

127
00:08:27,674 --> 00:08:29,776
ここで少し話を戻して

128
00:08:29,877 --> 00:08:33,647
SFrameについて
説明しますね

129
00:08:34,481 --> 00:08:39,186
SFrameとは
表形式のデータ構造で

130
00:08:39,285 --> 00:08:44,158
膨大なデータでも
機械学習モデルを作成できます

131
00:08:45,292 --> 00:08:48,795
一般的なデータ操作の
タスクも可能

132
00:08:48,896 --> 00:08:53,800
特定の行やカラムの
フィルタリングなどですね

133
00:08:55,536 --> 00:08:58,305
異なる種類のデータを
使用できます

134
00:08:58,805 --> 00:09:01,675
データをSFrameに
ロードすれば―

135
00:08:58,805 --> 00:09:01,675
データをSFrameに
ロードすれば―

136
00:09:01,775 --> 00:09:05,445
視覚的にデータを
確認できます

137
00:09:08,815 --> 00:09:12,085
SFrameで
できることは何か？

138
00:09:12,686 --> 00:09:14,721
物体検知で説明します

139
00:09:15,322 --> 00:09:19,059
Turi Createを
インポートした後―

140
00:09:19,159 --> 00:09:21,862
２つのSFrameを
ロードします

141
00:09:21,962 --> 00:09:24,431
１つはアノテーション

142
00:09:24,798 --> 00:09:27,601
もう１つは画像です

143
00:09:28,302 --> 00:09:33,607
関数“.explore”を使えば
データを視覚的に確認できます

144
00:09:34,174 --> 00:09:38,812
特定の行やカラムに
アクセスすることも可能

145
00:09:39,746 --> 00:09:44,618
もちろん
２つのSFrameを結合するとか

146
00:09:44,718 --> 00:09:49,156
保存しておくなどの
一般的な操作もできます

147
00:09:51,358 --> 00:09:55,562
次はモデルの作成です
またあの関数を使います

148
00:09:55,662 --> 00:09:59,867
“.create”が
面倒な仕事をこなして

149
00:09:59,967 --> 00:10:05,205
モデルをタスクに合わせて
カスタマイズするだけでなく

150
00:09:59,967 --> 00:10:05,205
モデルをタスクに合わせて
カスタマイズするだけでなく

151
00:10:05,305 --> 00:10:08,976
高品質で高精度に
作成してくれます

152
00:10:09,076 --> 00:10:14,314
これはデータの大小に
関係なく実行可能です

153
00:10:14,414 --> 00:10:18,585
たとえ１つの項目に対して
画像40枚ほどの―

154
00:10:18,819 --> 00:10:23,557
小さなデータでも
タスクは実行できます

155
00:10:23,657 --> 00:10:26,593
物体検知が可能です

156
00:10:29,196 --> 00:10:33,100
評価に移りましょう
先ほどと同様です

157
00:10:33,200 --> 00:10:37,404
“.evaluate”を使って
モデルを評価します

158
00:10:38,105 --> 00:10:42,242
物体検知の場合
考慮する要素は２つ

159
00:10:42,342 --> 00:10:45,045
正しいラベル付けと

160
00:10:45,479 --> 00:10:49,917
物体への境界ボックスの
正しい配置です

161
00:10:50,517 --> 00:10:54,755
この２つの要素で
単純なメトリックを作成し

162
00:10:54,855 --> 00:11:01,195
グラウンドトゥルースデータに対し
テストデータのスコアを予測

163
00:10:54,855 --> 00:11:01,195
グラウンドトゥルースデータに対し
テストデータのスコアを予測

164
00:11:01,328 --> 00:11:04,298
それに必要なのは
正しいラベルと

165
00:11:04,398 --> 00:11:10,270
さらにグラウンドトゥルースの
境界ボックスと比較した際に

166
00:11:10,370 --> 00:11:15,008
標準メトリックが予測のボックスで
５割は重なっていること

167
00:11:16,376 --> 00:11:21,682
この例では“コーヒー”と正しく
ラベル付けされていますが

168
00:11:21,782 --> 00:11:27,487
２つの境界ボックスは
約１割しか重なっていません

169
00:11:27,588 --> 00:11:29,923
正しい予測ではないですね

170
00:11:31,558 --> 00:11:34,294
こちらは重なりが広いものの

171
00:11:34,428 --> 00:11:36,997
ラベルが“バナナ”と
なっています

172
00:11:37,097 --> 00:11:40,234
この予測も
うまくいっていません

173
00:11:40,901 --> 00:11:43,136
この真ん中の例では

174
00:11:43,237 --> 00:11:48,175
７割が重なっており
“コーヒー”となっています

175
00:11:48,842 --> 00:11:53,380
テストデータで
すべての予測を実行して

176
00:11:53,547 --> 00:11:57,151
モデルの精度の
スコアを出すのです

177
00:11:59,119 --> 00:12:01,655
最後にデプロイを行います

178
00:11:59,119 --> 00:12:01,655
最後にデプロイを行います

179
00:12:01,788 --> 00:12:06,693
モデルをCore MLに
エクスポートしたら

180
00:12:06,894 --> 00:12:09,797
Xcodeに
ドラッグ＆ドロップで完了

181
00:12:10,597 --> 00:12:15,602
今週 物体検知の
新しい機能が出ました

182
00:12:15,736 --> 00:12:20,641
明日のCore MLの
セッションにご参加ください

183
00:12:20,741 --> 00:12:25,012
明日は 今日作った
物体検知モデルを使い

184
00:12:25,112 --> 00:12:28,115
デプロイについて説明します

185
00:12:30,150 --> 00:12:34,188
以上が Turi Createの
５段階のレシピでした

186
00:12:34,988 --> 00:12:38,525
(拍手)

187
00:12:38,692 --> 00:12:39,426
ありがとう

188
00:12:40,260 --> 00:12:43,730
次は同僚のザックが
デモを行います

189
00:12:47,267 --> 00:12:50,237
(拍手)

190
00:12:50,838 --> 00:12:51,872
ありがとう　アーロン

191
00:12:52,339 --> 00:12:56,810
では 早速コードを
書いてみましょう

192
00:12:56,910 --> 00:13:00,247
今から物体検知モデルを
作ります

193
00:12:56,910 --> 00:13:00,247
今から物体検知モデルを
作ります

194
00:13:09,923 --> 00:13:14,394
まずFinderで画像の
フォルダを見つけて

195
00:13:14,495 --> 00:13:16,563
これでモデルを訓練します

196
00:13:17,097 --> 00:13:19,266
このフォルダ“data”には

197
00:13:19,433 --> 00:13:22,569
食べ物の画像が
たくさんあります

198
00:13:22,669 --> 00:13:26,273
クロワッサンや
目玉焼きなどです

199
00:13:26,874 --> 00:13:31,979
朝食のデータですね
これでコードを書きます

200
00:13:32,880 --> 00:13:36,850
環境を
Jupyter Notebookにします

201
00:13:36,984 --> 00:13:39,920
これは Pythonの
対話型環境で

202
00:13:40,020 --> 00:13:43,290
コードのスニペットを入れれば
すぐに実行されるので

203
00:13:43,390 --> 00:13:46,693
インタラクティブな作業が
簡単です

204
00:13:46,793 --> 00:13:50,430
XcodeのPlaygroundと
似ていますね

205
00:13:50,964 --> 00:13:54,067
まずは Turi Createを
インポート

206
00:13:55,102 --> 00:13:56,336
“tc”とします

207
00:13:59,239 --> 00:14:02,776
これでスクリプトで
tcとして実行されます

208
00:13:59,239 --> 00:14:02,776
これでスクリプトで
tcとして実行されます

209
00:14:03,477 --> 00:14:05,679
さて 最初のタスクは

210
00:14:06,380 --> 00:14:07,981
データのロードです

211
00:14:10,951 --> 00:14:13,654
SFrameの形式で行います

212
00:14:14,087 --> 00:14:18,358
“images = tc.load images”と
入れたら

213
00:14:18,458 --> 00:14:21,929
先ほどのフォルダ名
“data”を入力

214
00:14:24,965 --> 00:14:29,503
Turi Createはデータを
参照し視覚化します

215
00:14:29,837 --> 00:14:34,942
SFrameの形式で
できたか確認してみます

216
00:14:35,075 --> 00:14:37,010
“.explore”を使います

217
00:14:37,344 --> 00:14:39,880
するとウインドウが開きます

218
00:14:39,980 --> 00:14:42,950
SFrameにカラムが
２つありますね

219
00:14:43,050 --> 00:14:47,321
１つはディスク上の
画像への相対パス

220
00:14:47,421 --> 00:14:51,859
もう１つは
画像のコンテンツです

221
00:14:51,959 --> 00:14:54,194
食べ物の画像が見えますね

222
00:14:54,561 --> 00:14:57,831
画像は正しく
ロードされたようです

223
00:14:59,766 --> 00:15:05,339
今度はアノテーションを
SFrame形式でロード

224
00:14:59,766 --> 00:15:05,339
今度はアノテーションを
SFrame形式でロード

225
00:15:08,175 --> 00:15:14,114
このファイル名を
“annotations.csv”とします

226
00:15:14,214 --> 00:15:19,019
このcsvは画像に対応した
アノテーションを含みます

227
00:15:22,022 --> 00:15:23,557
見てみましょう

228
00:15:23,757 --> 00:15:27,594
このSFrameの
パスのカラムは

229
00:15:27,694 --> 00:15:30,964
画像の相対パスを示しています

230
00:15:31,064 --> 00:15:34,601
アノテーションは
JSONオブジェクトを含み

231
00:15:34,701 --> 00:15:38,705
画像のラベルと
境界ボックスを示します

232
00:15:39,673 --> 00:15:41,708
データソースが
２つありますが

233
00:15:41,808 --> 00:15:45,078
モデルの訓練用に
１つにしたいですね

234
00:15:45,212 --> 00:15:46,780
２つを結合しましょう

235
00:15:46,980 --> 00:15:50,451
Turi Createでは
結合も簡単です

236
00:15:50,551 --> 00:15:55,956
“data = images.join
(annotations)”と入力

237
00:15:58,025 --> 00:16:01,995
SFrameにカラムが
３つできました

238
00:15:58,025 --> 00:16:01,995
SFrameにカラムが
３つできました

239
00:16:02,095 --> 00:16:06,033
パスに結合したので
それぞれの画像に

240
00:16:06,133 --> 00:16:08,769
アノテーションが
結びつきました

241
00:16:08,902 --> 00:16:11,939
これで情報がリンクしました

242
00:16:12,539 --> 00:16:14,408
ではモデルの訓練です

243
00:16:17,010 --> 00:16:18,979
新しいセクションを作ります

244
00:16:19,479 --> 00:16:21,248
名前は“Train a model”

245
00:16:24,785 --> 00:16:27,054
コードは１行で済みます

246
00:16:27,154 --> 00:16:30,724
“model =
tc.object detector.create”

247
00:16:30,824 --> 00:16:35,963
これは物体検知のタスクに
フォーカスしたAPIです

248
00:16:36,363 --> 00:16:39,466
さっきのSFrameの
データを渡して

249
00:16:39,566 --> 00:16:45,038
このデモ用に パラメータ
“max iterations”を入力

250
00:16:45,138 --> 00:16:47,541
通常 パラメータは不要です

251
00:16:47,641 --> 00:16:53,046
Turi Createがイテレーションの
回数を導き出すからです

252
00:16:53,347 --> 00:16:56,416
今回はイテレーションを
１回にして

253
00:16:56,517 --> 00:16:59,453
訓練をお見せします

254
00:16:59,720 --> 00:17:04,590
ここで時間がかかるのは
画像のサイズを変えるからで

255
00:16:59,720 --> 00:17:04,590
ここで時間がかかるのは
画像のサイズを変えるからで

256
00:17:04,691 --> 00:17:07,594
ニューラルネットワークに
かけるためです

257
00:17:07,694 --> 00:17:10,263
これは物体検知器の中で
行われます

258
00:17:10,364 --> 00:17:14,468
MacのGPUで
イテレーションを１回

259
00:17:16,336 --> 00:17:21,407
これは訓練が短時間なので
最高のモデルとは言えません

260
00:17:21,508 --> 00:17:25,179
なので ここは
料理番組の方式でいきます

261
00:17:25,279 --> 00:17:28,682
“作っておいた料理”を
出しますね

262
00:17:29,883 --> 00:17:32,553
“tc.load model”と入力し

263
00:17:33,253 --> 00:17:36,990
“breakfast-model.model”
を入力

264
00:17:38,058 --> 00:17:41,595
これが前もって
作っておいたものです

265
00:17:41,695 --> 00:17:46,900
画面を見ると物体検知器を使った
モデルだと分かります

266
00:17:47,100 --> 00:17:51,805
６つのクラスで
55分ほど訓練しました

267
00:17:51,905 --> 00:17:57,611
物体検知モデルを
１時間弱で訓練できたわけです

268
00:18:00,614 --> 00:18:05,119
次に このモデルの予測を
検証しましょう

269
00:18:11,125 --> 00:18:14,261
“Inspect predictions”の
セクションを作ります

270
00:18:14,361 --> 00:18:17,798
テストデータセットとして
ロードするのに

271
00:18:17,898 --> 00:18:22,069
SFrameの形式の
データを用意しました

272
00:18:22,336 --> 00:18:25,339
“test-breakfast-data.sframe”
です

273
00:18:25,539 --> 00:18:28,942
このSFrameには
重要な特質が２つ

274
00:18:29,042 --> 00:18:34,448
訓練に使ったのと同じ種類の
画像が含まれていることと

275
00:18:34,548 --> 00:18:39,353
モデルがこれらの
画像を見たことがないことです

276
00:18:39,453 --> 00:18:44,858
これでユーザのデータに
汎化できるか検証できます

277
00:18:47,027 --> 00:18:51,632
“model.predict”を
呼び出し

278
00:18:51,732 --> 00:18:56,870
用意したSFrameを使い
バッチ予測を行います

279
00:18:59,606 --> 00:19:02,743
これは数秒で終わります

280
00:18:59,606 --> 00:19:02,743
これは数秒で終わります

281
00:19:02,876 --> 00:19:06,447
検証しましょう
ランダムに選んでみます

282
00:19:06,547 --> 00:19:09,182
では“２”にしましょうか

283
00:19:09,483 --> 00:19:12,486
このJSONオブジェクトは

284
00:19:12,586 --> 00:19:16,223
訓練データと同じ形式で
予測されました

285
00:19:16,323 --> 00:19:21,595
高さや幅　xとyの座標と
“バナナ”というラベルが出ました

286
00:19:21,695 --> 00:19:26,200
モデルの信頼度は
約87パーセントですが

287
00:19:26,767 --> 00:19:30,204
これは人間には
解釈しにくいものです

288
00:19:30,304 --> 00:19:34,308
この画像が本当に
バナナなのか―

289
00:19:34,408 --> 00:19:38,846
座標の表す位置が
正確なのかも分かりません

290
00:19:39,580 --> 00:19:43,383
Turi Createには
境界ボックスを

291
00:19:43,484 --> 00:19:47,354
画像に正しく
描く機能があります

292
00:19:47,454 --> 00:19:49,189
やってみましょう

293
00:19:49,423 --> 00:19:54,194
さっきのテストSFrameに
予測画像のカラムを作り

294
00:19:54,928 --> 00:19:59,299
物体検知器のユーティリティの
出力を指定

295
00:19:59,399 --> 00:20:01,368
境界ボックスを作成します

296
00:19:59,399 --> 00:20:01,368
境界ボックスを作成します

297
00:20:02,369 --> 00:20:05,038
ボックスの作成に使うのは

298
00:20:05,572 --> 00:20:09,910
テスト画像のカラム
つまり画像そのものです

299
00:20:10,010 --> 00:20:13,947
さらにモデルから得た
予測も使います

300
00:20:14,248 --> 00:20:18,452
これで画像に
境界ボックスを描きます

301
00:20:18,552 --> 00:20:23,390
今度は画像形式で
先ほどの予測結果を表示します

302
00:20:24,892 --> 00:20:28,695
“.show”を使って
予測画像を確認します

303
00:20:28,796 --> 00:20:31,165
これで表示されました

304
00:20:31,365 --> 00:20:35,335
(拍手)

305
00:20:38,438 --> 00:20:43,410
このモデルは
１枚の写真には有効でしたが

306
00:20:43,510 --> 00:20:48,115
例えば５万枚の画像では
どうでしょうか？

307
00:20:48,549 --> 00:20:52,152
今度はモデルを量的に
評価してみます

308
00:20:53,120 --> 00:20:56,623
“Evaluate the model”の
セクションを作ります

309
00:20:56,857 --> 00:21:00,260
“model.evaluate”を
呼び出して

310
00:20:56,857 --> 00:21:00,260
“model.evaluate”を
呼び出して

311
00:21:00,661 --> 00:21:03,931
テストデータ全部を
評価します

312
00:21:06,133 --> 00:21:10,671
評価関数は
アーロンが説明したメトリックで

313
00:21:10,771 --> 00:21:15,876
境界ボックスと
ラベルの正確さを検証します

314
00:21:15,976 --> 00:21:20,180
これで訓練した６クラスの
結果が得られました

315
00:21:20,414 --> 00:21:23,717
境界ボックスとラベルが
示しているのは

316
00:21:23,817 --> 00:21:27,888
約80パーセントの確率で
“ベーグル”

317
00:21:27,988 --> 00:21:31,592
約67パーセントの確率で
“バナナ”です

318
00:21:32,326 --> 00:21:33,327
いい結果ですね

319
00:21:33,460 --> 00:21:37,598
実際のアプリケーションでも
使えるでしょうか？

320
00:21:37,898 --> 00:21:41,235
“export coreml”を使って

321
00:21:41,335 --> 00:21:44,471
Core MLモデルを作成

322
00:21:44,872 --> 00:21:47,608
“BreakfastModel.mlmodel”と
名付けます

323
00:21:47,708 --> 00:21:51,979
終わり次第
Finderで開きます

324
00:21:54,014 --> 00:21:56,049
エクスポートが
終了したらです

325
00:21:59,253 --> 00:22:00,687
Finderには

326
00:21:59,253 --> 00:22:00,687
Finderには

327
00:22:01,088 --> 00:22:03,557
“BreakfastModel.mlmodel”
があります

328
00:22:03,657 --> 00:22:08,595
Xcodeで開くと
Core MLモデルと同様の画面です

329
00:22:09,730 --> 00:22:11,565
入力された画像の記録と

330
00:22:11,698 --> 00:22:15,402
アウトプット項目では
信頼度と座標が見られます

331
00:22:15,502 --> 00:22:20,107
これで画像に対する
予測結果が分かりますね

332
00:22:20,240 --> 00:22:24,912
そしてiPhoneの
アプリケーションを使います

333
00:22:27,981 --> 00:22:29,683
僕のiPhoneにある―

334
00:22:29,850 --> 00:22:32,019
FoodPredictorです

335
00:22:32,252 --> 00:22:34,888
先ほど訓練した
モデルを使います

336
00:22:35,255 --> 00:22:40,294
写真を選びます
今日の朝食の写真にしましょう

337
00:22:40,394 --> 00:22:44,264
コーヒーとバナナは
僕の定番の朝食です

338
00:22:44,364 --> 00:22:47,501
バナナは めったに
食べないんですが

339
00:22:47,634 --> 00:22:49,770
今朝は例外ですね

340
00:22:52,039 --> 00:22:55,576
画像の境界ボックスを
タップします

341
00:22:55,676 --> 00:23:01,115
ボックス内の物体は
バナナだと表示されています

342
00:22:55,676 --> 00:23:01,115
ボックス内の物体は
バナナだと表示されています

343
00:23:01,782 --> 00:23:03,317
これはコーヒーですね

344
00:23:04,117 --> 00:23:05,786
(拍手)

345
00:23:15,996 --> 00:23:18,198
では まとめます

346
00:23:19,800 --> 00:23:23,937
まず画像とアノテーションを
SFrame形式にロード

347
00:23:24,037 --> 00:23:27,007
関数を呼び出して
データを結合

348
00:23:27,174 --> 00:23:31,078
Exploreメソッドで
対話式にデータを探す

349
00:23:31,712 --> 00:23:36,617
画像と境界ボックスと
ラベルのデータから

350
00:23:36,717 --> 00:23:40,320
高レベルのAPIを使って
モデルを作成

351
00:23:40,787 --> 00:23:46,360
モデルの評価では 質的には
アウトプットを抜き取り検査

352
00:23:46,460 --> 00:23:51,832
量的には タスクに使う
メトリックを求めました

353
00:23:52,232 --> 00:23:56,537
最後にモデルを
Core ML形式でエクスポート

354
00:23:58,605 --> 00:24:04,511
ここからはTuri Create 5.0の
新機能を紹介します

355
00:23:58,605 --> 00:24:04,511
ここからはTuri Create 5.0の
新機能を紹介します

356
00:24:06,980 --> 00:24:11,485
まずは Style Transferという
新しいタスク

357
00:24:12,453 --> 00:24:14,822
パフォーマンスについては

358
00:24:14,922 --> 00:24:17,891
ネイティブGPU
アクセラレーションで向上

359
00:24:19,226 --> 00:24:24,031
新たにパーソナライズのための
レコメンダモデルと

360
00:24:24,131 --> 00:24:28,469
Vision Feature Printによる
モデルをオプションで導入

361
00:24:28,569 --> 00:24:31,705
OSにあるモデルを
活用できます

362
00:24:33,574 --> 00:24:36,543
Style Transferのタスクには

363
00:24:36,977 --> 00:24:39,746
スタイル画像を使います

364
00:24:39,847 --> 00:24:44,818
例えば 印象に残りやすく
デザイン性の高い画像

365
00:24:44,918 --> 00:24:49,756
ここに蜂の巣状の画像と
花の画像があります

366
00:24:49,923 --> 00:24:54,561
写真に この画像の
フィルタをかけてみましょう

367
00:24:55,863 --> 00:24:57,564
この犬の写真に

368
00:24:57,664 --> 00:25:00,834
フィルタをかけてみますね

369
00:24:57,664 --> 00:25:00,834
フィルタをかけてみますね

370
00:25:01,201 --> 00:25:02,503
こうなりました

371
00:25:03,437 --> 00:25:08,442
複数の写真に
同じフィルタをかけられます

372
00:25:08,542 --> 00:25:10,577
猫と別の犬の写真では

373
00:25:10,777 --> 00:25:12,813
こんな感じになります

374
00:25:15,549 --> 00:25:17,284
アプリケーションを使って

375
00:25:17,384 --> 00:25:21,622
ユーザの写真に
フィルタをかけられます

376
00:25:25,025 --> 00:25:29,563
Style Transferモデルの
コード作成においても

377
00:25:29,663 --> 00:25:32,332
５段階のレシピを使います

378
00:25:32,432 --> 00:25:37,404
Turi Createをインポートし
SFrame形式でデータをロード

379
00:25:37,571 --> 00:25:40,908
高レベルのAPIで
モデルを作成

380
00:25:41,208 --> 00:25:45,012
予測をしたら
今度は関数“stylize”で

381
00:25:45,112 --> 00:25:47,781
画像にフィルタをかけます

382
00:25:48,081 --> 00:25:53,620
最後にCore ML形式で
エクスポートします

383
00:25:56,156 --> 00:26:01,028
次のデモでは
Style Transferモデルを作ります

384
00:25:56,156 --> 00:26:01,028
次のデモでは
Style Transferモデルを作ります

385
00:26:14,374 --> 00:26:17,344
Jupyter Notebookに戻って

386
00:26:17,444 --> 00:26:20,948
Turi Createをインポート

387
00:26:22,549 --> 00:26:23,717
“tc”とします

388
00:26:28,722 --> 00:26:33,060
画像を含むSFrameを
２つロードします

389
00:26:33,160 --> 00:26:36,497
１つはスタイル画像
“tc.load images”と入力

390
00:26:36,597 --> 00:26:38,866
ディレクトリ名は
“styles”

391
00:26:38,966 --> 00:26:41,835
もう１つは
コンテンツ画像です

392
00:26:42,836 --> 00:26:48,709
スタイル画像は写真などにかける
フィルタになります

393
00:26:48,809 --> 00:26:50,477
コンテンツ画像は―

394
00:26:50,577 --> 00:26:56,016
フィルタをかける写真などの
画像のことです

395
00:26:56,116 --> 00:26:59,219
今回は写真のことですね

396
00:26:59,720 --> 00:27:04,458
フォルダ“content”を
SFrameにロード

397
00:26:59,720 --> 00:27:04,458
フォルダ“content”を
SFrameにロード

398
00:27:05,125 --> 00:27:07,861
これでモデルを訓練できます

399
00:27:08,295 --> 00:27:13,600
“model =
tc.style transfer.create”と入力

400
00:27:13,700 --> 00:27:17,271
“style”と
“content”を渡します

401
00:27:18,205 --> 00:27:19,439
これだけです

402
00:27:20,007 --> 00:27:23,043
この訓練には
時間がかかるので

403
00:27:23,143 --> 00:27:28,048
今回も“作っておいた料理”を
お見せしますね

404
00:27:28,415 --> 00:27:31,452
“model = tc.load model”
と入力し

405
00:27:31,585 --> 00:27:35,622
訓練済みの
Style Transferモデルをロード

406
00:27:37,291 --> 00:27:42,229
どんなスタイル画像を使うのか
見てみましょう

407
00:27:43,897 --> 00:27:47,534
スタイルのSFrameの
画像カラムから

408
00:27:47,634 --> 00:27:51,338
スタイル“３”を見てみます

409
00:27:51,672 --> 00:27:54,208
積んである薪ですね

410
00:27:54,308 --> 00:27:57,044
印象的なパターンです

411
00:27:57,144 --> 00:28:01,648
これをフィルタにしたら
分かりやすいですね

412
00:27:57,144 --> 00:28:01,648
これをフィルタにしたら
分かりやすいですね

413
00:28:02,549 --> 00:28:05,786
コンテンツ画像も
見てみましょう

414
00:28:05,886 --> 00:28:09,857
テストデータセットを
ロードします

415
00:28:09,957 --> 00:28:15,529
これはアプリケーション実行時に
ユーザが持っている画像です

416
00:28:15,629 --> 00:28:19,433
モデルは訓練時に
この画像を見ていません

417
00:28:19,533 --> 00:28:21,835
テスト画像で評価して

418
00:28:21,935 --> 00:28:25,505
ユーザのデータに
汎化可能か見てみます

419
00:28:26,440 --> 00:28:28,942
まずテストデータセットを
ロード

420
00:28:30,510 --> 00:28:33,413
関数“tc.load images”で

421
00:28:33,614 --> 00:28:36,283
フォルダ“test”を呼び出します

422
00:28:36,917 --> 00:28:40,988
テストデータセットから
サンプルを１枚選びます

423
00:28:41,088 --> 00:28:44,925
最初の画像を
取り出すことにしましょう

424
00:28:46,093 --> 00:28:48,829
“.show”を呼び出し

425
00:28:50,430 --> 00:28:53,600
フィルタなしの写真を
表示させます

426
00:28:53,901 --> 00:28:55,636
これは僕の猫です

427
00:28:59,039 --> 00:29:00,407
いつもこんな感じ

428
00:28:59,039 --> 00:29:00,407
いつもこんな感じ

429
00:29:01,742 --> 00:29:07,347
では 訓練したモデルで
画像のスタイルを変換します

430
00:29:08,782 --> 00:29:13,687
“stylized image =
model.stylize”と入力

431
00:29:13,854 --> 00:29:16,924
関数が“stylize”なのは

432
00:29:17,024 --> 00:29:20,694
Style Transferのタスクに
特化しているからです

433
00:29:20,794 --> 00:29:23,730
サンプルの画像を渡します

434
00:29:23,831 --> 00:29:26,366
スタイルは“３”です

435
00:29:26,467 --> 00:29:30,470
さっきの薪の画像を
使うからです

436
00:29:32,339 --> 00:29:35,175
スタイルを変換した画像を
見てみます

437
00:29:36,443 --> 00:29:38,178
“.show”を使います

438
00:29:38,278 --> 00:29:40,881
猫が薪みたいになりました

439
00:29:40,981 --> 00:29:43,484
(拍手)

440
00:29:47,120 --> 00:29:49,456
他のスタイルも試してみます

441
00:29:49,790 --> 00:29:53,660
別のスタイルに
画像を変換しますね

442
00:29:53,961 --> 00:29:55,229
使うのは…

443
00:29:58,165 --> 00:29:59,700
さっきのサンプル画像です

444
00:29:59,933 --> 00:30:03,303
スタイルは“７”に
してみます

445
00:29:59,933 --> 00:30:03,303
スタイルは“７”に
してみます

446
00:30:05,105 --> 00:30:06,874
どうなるでしょう

447
00:30:12,780 --> 00:30:16,483
いいですね
フィルタはどれでしょうか？

448
00:30:16,583 --> 00:30:19,219
スタイル画像を見てみます

449
00:30:25,192 --> 00:30:26,793
スタイル画像の７

450
00:30:28,262 --> 00:30:32,332
“.show”を使って
表示させます

451
00:30:32,432 --> 00:30:36,103
これが猫にかけた
フィルタですね

452
00:30:37,471 --> 00:30:39,740
Style Transferモデルが
完成したので

453
00:30:39,840 --> 00:30:42,976
“model.export coreml”を
呼び出し

454
00:30:43,076 --> 00:30:47,047
Core ML形式で保存します

455
00:30:52,486 --> 00:30:56,190
今度は iPhoneの
アプリケーションを使い

456
00:30:56,290 --> 00:30:58,625
フィルタをかけます

457
00:31:01,929 --> 00:31:06,266
Style Transferという
アプリケーションを起動し

458
00:31:06,567 --> 00:31:10,938
Photo Libraryで
写真を選びます

459
00:31:12,005 --> 00:31:13,540
僕の犬の写真です

460
00:31:16,276 --> 00:31:17,544
名前はライカー

461
00:31:18,345 --> 00:31:21,982
このアプリケーションで
使用可能なスタイルは

462
00:31:22,082 --> 00:31:24,818
スクロールして見られます

463
00:31:24,918 --> 00:31:30,757
１つのモデルを訓練するのに
全部のスタイル画像を使いましたね

464
00:31:30,858 --> 00:31:33,894
モデル１つで
複数のスタイルができるので

465
00:31:33,994 --> 00:31:38,198
アプリケーションの
容量は増えません

466
00:31:39,032 --> 00:31:42,035
ライカーにかけたスタイルは―

467
00:31:43,937 --> 00:31:44,872
いい感じです

468
00:31:52,546 --> 00:31:53,447
では…

469
00:31:53,547 --> 00:31:58,585
(拍手)

470
00:31:58,685 --> 00:32:00,621
では要約します

471
00:31:58,685 --> 00:32:00,621
では要約します

472
00:32:00,821 --> 00:32:03,423
画像を
SFrame形式でロード

473
00:32:03,524 --> 00:32:07,628
スタイルとコンテンツ画像を
２つのSFrameへ

474
00:32:07,728 --> 00:32:11,432
高レベルのAPIで
作成したモデルは

475
00:32:11,532 --> 00:32:16,103
スタイルとコンテンツの画像に
直接作用します

476
00:32:16,336 --> 00:32:21,141
このモデルを検証するため
画像のスタイルを変換し―

477
00:32:21,241 --> 00:32:23,977
予測結果を視覚化します

478
00:32:24,111 --> 00:32:28,415
最後にCore ML形式で
モデルをエクスポート

479
00:32:30,484 --> 00:32:34,655
Turi Create 5.0の
他の機能を紹介します

480
00:32:34,955 --> 00:32:37,391
まずは Macの
GPUアクセラレーション

481
00:32:37,491 --> 00:32:41,528
パフォーマンスが
画像分類では12倍向上

482
00:32:41,628 --> 00:32:45,566
物体検知では９倍です
iMac Proを使った場合です

483
00:32:46,133 --> 00:32:50,204
(拍手)

484
00:32:50,971 --> 00:32:54,675
Core ML形式の
エクスポートに使える新しいタスク

485
00:32:54,775 --> 00:32:56,243
パーソナライゼーションも
あります

486
00:32:56,343 --> 00:32:59,079
これはユーザの履歴から

487
00:32:59,179 --> 00:33:02,182
レコメンドすることです

488
00:32:59,179 --> 00:33:02,182
レコメンドすることです

489
00:33:02,783 --> 00:33:07,254
モデルはCore MLの
カスタムモデルでデプロイされます

490
00:33:07,354 --> 00:33:11,458
macOS Mojaveと
iOS 12で使えます

491
00:33:11,592 --> 00:33:15,562
これはオープンソースにしてから
要望が多かったので

492
00:33:15,662 --> 00:33:17,898
紹介できてうれしく思います

493
00:33:19,199 --> 00:33:22,770
(拍手)

494
00:33:23,771 --> 00:33:28,041
レコメンダモデルは
他のCore MLモデルと同じです

495
00:33:28,141 --> 00:33:32,813
一番下のセクション
“Dependencies”には

496
00:33:32,913 --> 00:33:36,750
カスタムモデルを
使っているとあります

497
00:33:36,850 --> 00:33:39,286
TCRecommenderです

498
00:33:39,386 --> 00:33:42,756
Turi Createは
カスタムモデルAPIを通して

499
00:33:42,856 --> 00:33:45,859
Core MLのレコメンダを
サポートします

500
00:33:47,528 --> 00:33:52,099
使い方は
他のCore MLモデルとほぼ同じ

501
00:33:52,199 --> 00:33:54,301
モデルをインスタンス化して

502
00:33:54,635 --> 00:33:59,173
インプットを作り アバターの
作成アプリケーションを作りました

503
00:33:59,273 --> 00:34:01,975
ユーザは茶色のあごヒゲに―

504
00:33:59,273 --> 00:34:01,975
ユーザは茶色のあごヒゲに―

505
00:34:02,075 --> 00:34:06,380
口ヒゲとロングヘアを
アバターに選んでますね

506
00:34:06,480 --> 00:34:11,217
こうした対話をインプットとして
このモデルから予測できます

507
00:34:11,351 --> 00:34:16,790
“k: 10”とはトップテン予測を
出すということです

508
00:34:19,393 --> 00:34:21,428
では 今日のまとめです

509
00:34:22,161 --> 00:34:25,431
Turi Createでは
Core MLモデルを作り

510
00:34:25,532 --> 00:34:28,635
インテリジェントな機能を
実現できます

511
00:34:28,735 --> 00:34:31,371
使うのは５段階のレシピです

512
00:34:31,471 --> 00:34:36,844
最初にタスクを確認し
機械学習タスクにすること

513
00:34:36,944 --> 00:34:41,447
データを集めて注釈をつけ
モデルの訓練に使うこと

514
00:34:42,049 --> 00:34:47,821
タスクに合った高レベルのAPIを
使ってモデルを訓練すること

515
00:34:48,355 --> 00:34:53,159
質的にも量的にも
モデルを評価すること

516
00:34:53,260 --> 00:34:56,864
最後にCore ML形式で
デプロイすること

517
00:34:59,133 --> 00:35:03,971
このレシピでコードを作成します
まずTuri Createをインポート

518
00:34:59,133 --> 00:35:03,971
このレシピでコードを作成します
まずTuri Createをインポート

519
00:35:04,304 --> 00:35:06,807
データをSFrame形式に
ロード

520
00:35:06,907 --> 00:35:10,611
タスクに合ったAPIで
モデルを作成

521
00:35:11,011 --> 00:35:16,383
同じくタスクに合った評価関数で
モデルを評価

522
00:35:16,517 --> 00:35:20,354
“export coreml”で
エクスポートしてデプロイ

523
00:35:21,855 --> 00:35:25,526
Turi Createは
機械学習タスクをサポートします

524
00:35:25,626 --> 00:35:30,597
画像分類やテキスト分類などの
高レベルのタスクから

525
00:35:30,698 --> 00:35:36,570
データの回帰や分類など
低レベルのタスクまでです

526
00:35:37,871 --> 00:35:42,542
インテリジェントな機能を
作成したモデルで実装できます

527
00:35:42,643 --> 00:35:46,847
物体検知や
スタイル変換などの機能です

528
00:35:48,415 --> 00:35:53,520
詳しくはdeveloper.apple.comの
セッションで

529
00:35:53,620 --> 00:35:58,092
ラボは今日と金曜の午後に
やっています

530
00:35:58,192 --> 00:36:02,162
フィードバック歓迎です
質問にもお答えします

531
00:35:58,192 --> 00:36:02,162
フィードバック歓迎です
質問にもお答えします

532
00:36:02,262 --> 00:36:06,667
今日お見せしたデモも
ご覧いただけます

533
00:36:07,067 --> 00:36:07,834
ありがとう

534
00:36:07,935 --> 00:36:10,204
(拍手)