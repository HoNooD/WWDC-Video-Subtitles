
1
00:00:07,040 --> 00:00:16,683
(音楽)

2
00:00:19,586 --> 00:00:26,460
(拍手)

3
00:00:27,561 --> 00:00:32,031
オブジェクトトラッキングに
ついてお話しします

4
00:00:32,665 --> 00:00:36,069
Visionの問題に
直面したことは？

5
00:00:36,603 --> 00:00:40,040
もしあれば
MacであれiOSであれ

6
00:00:40,140 --> 00:00:43,110
このセッションが
役に立つでしょう

7
00:00:43,310 --> 00:00:44,645
私 カメンスキーが

8
00:00:44,745 --> 00:00:47,981
Visionのフレームワークに
ついてお話しします

9
00:00:51,585 --> 00:00:53,587
アジェンダは４つです

10
00:00:53,687 --> 00:00:55,989
まず なぜVisionか？

11
00:00:56,190 --> 00:01:00,194
次は本年度の
最新情報についてです

12
00:00:56,190 --> 00:01:00,194
次は本年度の
最新情報についてです

13
00:01:00,827 --> 00:01:04,965
そして
Vision APIについてお話しします

14
00:01:05,465 --> 00:01:10,604
最後は本日のメインの
トラッキングについてです

15
00:01:13,874 --> 00:01:14,942
なぜVisionか？

16
00:01:17,811 --> 00:01:23,617
コンピュータービジョンに関する
あらゆる問題を解消するために

17
00:01:24,051 --> 00:01:28,555
シンプルで一貫性のある
インターフェイスにしました

18
00:01:28,655 --> 00:01:33,260
iOSとmacOSと
tvOSで稼働します

19
00:01:34,127 --> 00:01:35,762
プライバシーを重視し

20
00:01:35,863 --> 00:01:41,068
デバイス内のデータが
流出しないようにしています

21
00:01:42,202 --> 00:01:43,971
我々は常に進化し―

22
00:01:44,471 --> 00:01:49,042
アルゴリズムを改善し
新開発にも取り組んでいます

23
00:01:51,512 --> 00:01:53,113
Visionの基礎を見ましょう

24
00:01:54,515 --> 00:01:59,753
Vision APIとの
インタラクションにおいて

25
00:02:00,254 --> 00:02:03,690
何をどう処理し
結果をどこで見るか？

26
00:02:04,658 --> 00:02:07,327
何を処理するかというと

27
00:02:07,694 --> 00:02:09,763
皆さんのリクエストです

28
00:02:10,364 --> 00:02:14,134
どのように
処理するかというと

29
00:02:14,234 --> 00:02:18,472
リクエストハンドラや
エンジンを使います

30
00:02:19,006 --> 00:02:23,610
結果は
オブザベーションとして出ます

31
00:02:24,444 --> 00:02:25,946
ご覧ください

32
00:02:26,180 --> 00:02:31,218
これは今回のセッションで
最も重要なスライドの１つです

33
00:02:31,318 --> 00:02:37,824
リクエストやリクエストハンドラ
オブザベーションを示しています

34
00:02:42,229 --> 00:02:44,064
まずはリクエストです

35
00:02:44,164 --> 00:02:47,201
本日ご用意した
リクエストです

36
00:02:47,534 --> 00:02:52,606
様々なディテクタがあり
画像登録処理や―

37
00:02:52,706 --> 00:02:56,143
トラッカーに加え
Core MLリクエストもあります

38
00:02:56,243 --> 00:02:59,980
VisionとCore MLの
併用については

39
00:03:00,080 --> 00:03:06,086
同僚のフランが行う
次のセッションでお話しします

40
00:03:08,455 --> 00:03:10,190
リクエストハンドラです

41
00:03:11,124 --> 00:03:13,994
VNImageRequestHandlerと

42
00:03:14,094 --> 00:03:16,430
VNSequenceRequestHandlerが
あります

43
00:03:16,530 --> 00:03:19,099
比較してみましょう

44
00:03:20,200 --> 00:03:22,169
まずは
VNImageRequestHandler

45
00:03:24,004 --> 00:03:28,942
同じイメージで１つ以上の
リクエストを処理します

46
00:03:30,010 --> 00:03:35,716
ここにはイメージの派生物などの
情報をキャッシュして

47
00:03:35,816 --> 00:03:39,286
他のパイプライン上の
リクエストで使います

48
00:03:39,887 --> 00:03:43,924
例えば
ニューラルネットワークは

49
00:03:44,024 --> 00:03:48,395
カラースキームのしかるべき
イメージを持ちます

50
00:03:48,495 --> 00:03:53,233
例えば 500×500で白黒と
予想した場合

51
00:03:53,800 --> 00:03:57,004
その形式の
ユーザ入力はまれです

52
00:03:57,104 --> 00:03:59,640
そこでイメージを変換します

53
00:03:59,740 --> 00:04:02,910
ニューラルネットワークに
入れる情報を

54
00:03:59,740 --> 00:04:02,910
ニューラルネットワークに
入れる情報を

55
00:04:03,010 --> 00:04:06,480
リクエストハンドラでも
キャッシュします

56
00:04:06,580 --> 00:04:12,719
次に同一の形式を使う際に
再計算の必要がありません

57
00:04:13,187 --> 00:04:17,891
リクエストの結果もキャッシュし
パイプライン上で使えます

58
00:04:17,991 --> 00:04:21,428
パイプラインを
見ていきましょう

59
00:04:22,930 --> 00:04:24,865
SequenceRequestHandlerは

60
00:04:25,499 --> 00:04:31,839
フレームのシーケンス内での
トラッキングなどに使われます

61
00:04:32,406 --> 00:04:35,509
シーケンス全体にわたって
フレーム間の―

62
00:04:35,609 --> 00:04:38,512
オペレーション状況を
キャッシュします

63
00:04:39,546 --> 00:04:43,750
Visionではトラッキングや
画像登録処理などに使われ

64
00:04:43,884 --> 00:04:46,987
その他の処理は
ImageRequestHandlerによります

65
00:04:51,124 --> 00:04:54,928
結果は
オブザベーションから出ます

66
00:04:55,295 --> 00:05:01,401
これはVNObservationから
派生するクラスの集合体です

67
00:04:55,295 --> 00:05:01,401
これはVNObservationから
派生するクラスの集合体です

68
00:05:01,501 --> 00:05:03,070
取得の方法は？

69
00:05:03,537 --> 00:05:05,639
１つ目の方法は

70
00:05:05,739 --> 00:05:11,812
リクエストの処理後に
結果のプロパティを見ることです

71
00:05:11,912 --> 00:05:14,615
それで処理結果が分かります

72
00:05:16,483 --> 00:05:19,353
２つ目は手動で作成します

73
00:05:19,820 --> 00:05:22,789
後ほど これらの例を
ご覧ください

74
00:05:27,327 --> 00:05:30,030
今年の最新情報をお話しします

75
00:05:30,330 --> 00:05:33,066
まずは
新しいフェイスディテクタです

76
00:05:34,835 --> 00:05:39,439
より多くの顔を
方向に関係なく検出できます

77
00:05:39,773 --> 00:05:44,244
一例として
７人の顔の画像を見てみましょう

78
00:05:44,444 --> 00:05:49,049
昨年のディテクタで
検出できる顔は３つです

79
00:05:49,149 --> 00:05:52,953
これらは
直立姿勢に近い人の顔です

80
00:05:53,854 --> 00:05:57,858
新しいディテクタで
処理すると

81
00:05:57,958 --> 00:06:01,895
ご覧のように
すべての顔が検出されます

82
00:05:57,958 --> 00:06:01,895
ご覧のように
すべての顔が検出されます

83
00:06:04,031 --> 00:06:06,066
詳しく見ましょう

84
00:06:06,166 --> 00:06:09,736
(拍手)

85
00:06:15,042 --> 00:06:20,614
このディテクタは昨年と
同じAPIを使っています

86
00:06:20,714 --> 00:06:25,652
修正事項を特定する時は
プロパティを上書きして

87
00:06:25,752 --> 00:06:28,288
ユーザのRevision2と
設定します

88
00:06:28,388 --> 00:06:30,657
理由はあとで説明します

89
00:06:31,525 --> 00:06:34,361
新規プロパティも
２つ導入しました

90
00:06:34,461 --> 00:06:37,698
１つは 回転
頭のこんな動きです

91
00:06:37,798 --> 00:06:41,235
もう１つは 方位変更
首を軸にした動きです

92
00:06:45,005 --> 00:06:49,543
我々は新たなアルゴリズムを
導入する際でも

93
00:06:49,643 --> 00:06:51,945
旧版を即座に廃止しません

94
00:06:52,045 --> 00:06:57,985
新旧両方の修正事項を
ある程度の期間は維持します

95
00:06:58,385 --> 00:07:02,823
プロパティを特定し
処理の方法を決めます

96
00:06:58,385 --> 00:07:02,823
プロパティを特定し
処理の方法を決めます

97
00:07:03,957 --> 00:07:07,661
デフォルトの動作もあります

98
00:07:07,761 --> 00:07:11,131
リクエストオブジェクトを
作成する際に

99
00:07:11,231 --> 00:07:14,368
指示を与えないと
こうなります

100
00:07:14,735 --> 00:07:21,208
アプリケーションがリンクしている
SDKのリクエストの

101
00:07:21,308 --> 00:07:23,911
直近の修正事項が出てきます

102
00:07:24,011 --> 00:07:26,613
重要なので例を紹介します

103
00:07:26,980 --> 00:07:30,484
昨年のSDKに
リンクしているとします

104
00:07:30,584 --> 00:07:33,086
昨年は単一のディテクタです

105
00:07:33,187 --> 00:07:35,222
コンパイルせずに使うと

106
00:07:35,455 --> 00:07:39,693
昨年のディテクタしか
使えないのです

107
00:07:40,460 --> 00:07:44,932
その一方で
コードや座標を変更せずに―

108
00:07:45,032 --> 00:07:48,702
アプリケーションを
コンパイルし直すとします

109
00:07:48,802 --> 00:07:53,040
そうすればデフォルトで
Revision2となるのです

110
00:07:54,808 --> 00:07:59,313
アプリケーションを最新に
保ってください

111
00:07:59,413 --> 00:08:02,816
次のステップが
常に決まるのです

112
00:07:59,413 --> 00:08:02,816
次のステップが
常に決まるのです

113
00:08:02,916 --> 00:08:07,154
皆さんが引用するアルゴリズムの
パフォーマンスは

114
00:08:07,254 --> 00:08:08,622
お分かりでしょう

115
00:08:08,722 --> 00:08:12,159
アプリケーションは
最新の状態に保てます

116
00:08:12,259 --> 00:08:17,865
例えば特定の修正事項を
数年後に廃止して

117
00:08:18,065 --> 00:08:20,901
新たにコード化できます

118
00:08:25,405 --> 00:08:29,576
次はVision APIとの
インタラクションです

119
00:08:32,011 --> 00:08:34,548
イメージリクエストハンドラの
例を見ます

120
00:08:35,549 --> 00:08:40,888
同一のイメージで１つ以上の
処理を行います

121
00:08:42,489 --> 00:08:47,060
リクエスト結果などの情報を
キャッシュし―

122
00:08:47,194 --> 00:08:52,499
連続したリクエストで
その情報を使えます

123
00:08:53,333 --> 00:08:54,701
サンプルコードを見ます

124
00:08:56,904 --> 00:09:02,743
このサンプルのポイントを
強調しておきましょう

125
00:08:56,904 --> 00:09:02,743
このサンプルのポイントを
強調しておきましょう

126
00:09:03,277 --> 00:09:06,280
エラーハンドリングは
いい例ではありません

127
00:09:06,380 --> 00:09:09,383
強制アンラップを使います

128
00:09:09,616 --> 00:09:11,785
望まない動作を防ぐため

129
00:09:11,885 --> 00:09:16,223
暗号化する際は
ガードを使うべきです

130
00:09:17,157 --> 00:09:23,163
imageURLを使って
リクエストハンドラを作成します

131
00:09:23,497 --> 00:09:27,467
ファイルが置かれている
SSDの場です

132
00:09:28,402 --> 00:09:29,736
例を見ましょう

133
00:09:30,637 --> 00:09:34,441
まず顔検出の
リクエストを作成します

134
00:09:35,042 --> 00:09:38,979
次にImageRequestHandlerを
作成して

135
00:09:39,146 --> 00:09:42,482
imageURLを渡します

136
00:09:43,116 --> 00:09:46,420
そしてハンドラに
リクエストを処理させます

137
00:09:46,653 --> 00:09:48,622
最後に結果を見ます

138
00:09:49,890 --> 00:09:55,195
顔が１つ写っている画像の
結果はこちらです

139
00:10:00,000 --> 00:10:03,103
オブザベーションを
取得します

140
00:10:03,203 --> 00:10:07,608
顔が配置されている
境界ボックスが重要です

141
00:10:09,376 --> 00:10:10,944
ご覧ください

142
00:10:11,044 --> 00:10:16,517
最初の３行だけで
画像内の顔が見つかるのです

143
00:10:18,118 --> 00:10:22,589
(拍手)

144
00:10:22,689 --> 00:10:24,725
次は
シーケンスリクエストハンドラです

145
00:10:27,861 --> 00:10:30,430
シーケンス上での
トラッキングなど

146
00:10:30,531 --> 00:10:34,201
特定の操作プロセスで
使います

147
00:10:35,369 --> 00:10:39,439
このサンプルコードは
最もシンプルな―

148
00:10:39,540 --> 00:10:42,676
Vision APIの
トラッキングシーケンスです

149
00:10:43,710 --> 00:10:46,413
まずリクエストハンドラを
作成します

150
00:10:47,381 --> 00:10:51,185
次に
DetectedObjectObservationで

151
00:10:51,318 --> 00:10:54,321
トラッキングする対象を
特定します

152
00:10:54,421 --> 00:10:57,724
これで境界ボックスが
取得できます

153
00:10:58,759 --> 00:11:01,261
トラッキング
シーケンスを開始します

154
00:10:58,759 --> 00:11:01,261
トラッキング
シーケンスを開始します

155
00:11:01,662 --> 00:11:05,833
５つの連続したフレームで
トラッキングします

156
00:11:06,767 --> 00:11:08,569
見てみましょう

157
00:11:08,702 --> 00:11:13,941
フレームをフィードする
オブジェクトがあります

158
00:11:14,208 --> 00:11:15,742
フレームを取得します

159
00:11:16,510 --> 00:11:21,081
リクエストを作成し
DetectedObjectObservationを

160
00:11:21,181 --> 00:11:24,117
イニシャライザ付きで
パラメータとして渡します

161
00:11:24,218 --> 00:11:27,087
ループの始動前に
作成しました

162
00:11:28,622 --> 00:11:31,859
リクエストハンドラに
処理を依頼します

163
00:11:33,660 --> 00:11:38,799
ここで結果を分析して
さらなる作業を行います

164
00:11:39,199 --> 00:11:40,300
最後です

165
00:11:41,201 --> 00:11:43,570
これは非常に重要です

166
00:11:43,670 --> 00:11:48,141
結果を当該ループから
取り出して次に渡します

167
00:11:48,242 --> 00:11:52,179
次のループリクエスト作成後に
結果を見ます

168
00:11:53,514 --> 00:11:58,051
５つのフレームに
収めたい場合の結果です

169
00:12:06,360 --> 00:12:07,828
リクエストオブジェクトの
作成法は？

170
00:12:09,563 --> 00:12:13,267
リクエストには
２種類のプロパティがあります

171
00:12:13,367 --> 00:12:16,570
必須のものと
オプショナルのものです

172
00:12:17,037 --> 00:12:19,339
必須のプロパティは

173
00:12:19,439 --> 00:12:24,711
リクエストオブジェクト作成のため
イニシャライザを経由します

174
00:12:25,879 --> 00:12:27,014
例を見ましょう

175
00:12:28,415 --> 00:12:31,418
先ほどスライド上で
見たものです

176
00:12:31,518 --> 00:12:36,690
TrackObjectRequestの
イニシャライザに渡された―

177
00:12:36,790 --> 00:12:38,892
オブザベーションは
必須プロパティの例です

178
00:12:40,561 --> 00:12:42,162
オプショナルの
ものもあります

179
00:12:43,330 --> 00:12:45,632
どちらのプロパティも

180
00:12:45,732 --> 00:12:49,670
リクエストオブジェクトが
宣言されている場所にあります

181
00:12:50,904 --> 00:12:55,742
オプショナルには
重要なデフォルトがあります

182
00:12:55,843 --> 00:13:00,047
これを初期化しますが
上書きも可能です

183
00:12:55,843 --> 00:13:00,047
これを初期化しますが
上書きも可能です

184
00:13:00,414 --> 00:13:01,548
例を見ましょう

185
00:13:05,786 --> 00:13:09,056
DetectBarcodesRequest
オブジェクトです

186
00:13:09,490 --> 00:13:14,862
リクエストハンドラに
フィードさせるだけであれば

187
00:13:14,962 --> 00:13:18,665
バーコードを探し
イメージ全体で処理します

188
00:13:19,066 --> 00:13:24,771
しかしここでは
小さな部分を特定します

189
00:13:24,872 --> 00:13:27,875
ここでは
バーコードにフォーカスし

190
00:13:28,108 --> 00:13:30,978
プロパティの上書きをします

191
00:13:31,345 --> 00:13:34,214
ハンドラにフィードした場合

192
00:13:34,348 --> 00:13:37,384
小さな部分のみに
フォーカスするのです

193
00:13:38,118 --> 00:13:43,090
オプショナルのプロパティの
例を見てください

194
00:13:43,657 --> 00:13:47,494
取得した
リクエストオブジェクトは

195
00:13:47,761 --> 00:13:51,164
完全に構築された
オブジェクトです

196
00:13:51,532 --> 00:13:55,536
いつでも使用を開始できます

197
00:13:55,636 --> 00:13:59,873
あとからでもプロパティを
上書きできますが

198
00:13:59,973 --> 00:14:03,443
オブジェクトがある時は
作業すべきです

199
00:13:59,973 --> 00:14:03,443
オブジェクトがある時は
作業すべきです

200
00:14:07,414 --> 00:14:13,420
次のセッションで
より詳しくご説明するのが

201
00:14:13,987 --> 00:14:15,889
境界ボックスです

202
00:14:16,089 --> 00:14:20,627
受け取る座標は
正規化されています

203
00:14:20,727 --> 00:14:24,765
位置座標が０から１の範囲です

204
00:14:25,032 --> 00:14:29,870
詳細は次のセッションで
ご確認ください

205
00:14:33,607 --> 00:14:35,409
次は結果をどう見るか

206
00:14:37,044 --> 00:14:40,481
結果はオブザベーションとして
出てきます

207
00:14:41,648 --> 00:14:45,886
結果のプロパティを通して
追加されます

208
00:14:46,353 --> 00:14:48,055
オブザベーション数は？

209
00:14:49,756 --> 00:14:51,959
０からＮまであります

210
00:14:52,492 --> 00:14:55,896
もう１つの
アスペクトがあります

211
00:14:55,996 --> 00:15:01,635
nilはリクエストの失敗で
０とは異なります

212
00:14:55,996 --> 00:15:01,635
nilはリクエストの失敗で
０とは異なります

213
00:15:01,835 --> 00:15:06,306
０は探しているものが
ないということです

214
00:15:06,740 --> 00:15:09,710
フェイスディテクタを
例に出しましょう

215
00:15:10,711 --> 00:15:14,648
顔のない画像を
フィードすれば０です

216
00:15:15,315 --> 00:15:19,219
１つ以上の顔を
フィードさせれば

217
00:15:19,453 --> 00:15:22,156
適切な数の
オブザベーションが出ます

218
00:15:24,258 --> 00:15:28,829
そしてオブザベーションは
変更できません

219
00:15:28,929 --> 00:15:32,065
使用されている例を
見ましょう

220
00:15:33,200 --> 00:15:39,072
注目していただきたい
プロパティがあと２つあります

221
00:15:39,173 --> 00:15:43,710
１つは 一意のIDで
しかるべき結果が出る―

222
00:15:43,877 --> 00:15:46,813
処理ステップを特定します

223
00:15:47,481 --> 00:15:49,316
もう１つは信頼度です

224
00:15:50,250 --> 00:15:54,488
どのくらいの確証で出た
結果か分かります

225
00:15:55,489 --> 00:15:58,959
信頼度は０から１です

226
00:15:59,059 --> 00:16:02,763
次のセッションで詳しく
お話しします

227
00:15:59,059 --> 00:16:02,763
次のセッションで詳しく
お話しします

228
00:16:07,134 --> 00:16:08,869
次はパイプラインです

229
00:16:09,670 --> 00:16:10,771
パイプラインとは？

230
00:16:11,605 --> 00:16:15,275
リクエスト１が
２の実行に依存しており

231
00:16:15,375 --> 00:16:20,380
２が３の実行に
依存しているとしましょう

232
00:16:22,015 --> 00:16:26,587
この状態で
シーケンスを処理するには？

233
00:16:26,687 --> 00:16:30,257
まずはリクエスト３の
処理をします

234
00:16:30,357 --> 00:16:34,194
その結果を２に
フィードします

235
00:16:34,328 --> 00:16:36,530
同じことを２で行い

236
00:16:36,630 --> 00:16:39,333
最後に１の処理をします

237
00:16:41,568 --> 00:16:44,071
この例ではパイプラインを

238
00:16:44,371 --> 00:16:47,941
暗黙的･明示的な順序で
稼働させました

239
00:16:48,208 --> 00:16:53,981
次はフェイスランドマーク
ディテクタを稼働します

240
00:16:54,381 --> 00:16:58,285
フェイスランドマークは
顔の特徴です

241
00:16:58,385 --> 00:17:02,222
両目 眉 鼻 口の
配置のことです

242
00:16:58,385 --> 00:17:02,222
両目 眉 鼻 口の
配置のことです

243
00:17:02,890 --> 00:17:06,093
これに暗黙的順序を
適用するには？

244
00:17:13,901 --> 00:17:16,970
すでに見たものと似ています

245
00:17:17,069 --> 00:17:19,506
顔の特徴のリクエストを作り

246
00:17:20,440 --> 00:17:23,042
ImageRequestHandlerを
作成します

247
00:17:23,710 --> 00:17:25,579
そしてリクエストの処理です

248
00:17:26,113 --> 00:17:28,281
最後に結果を見ます

249
00:17:28,916 --> 00:17:33,187
１つの顔を含む画像なら
結果はこうなります

250
00:17:35,255 --> 00:17:37,357
シーケンスをたどります

251
00:17:39,193 --> 00:17:40,094
結果です

252
00:17:40,694 --> 00:17:44,398
顔の境界ボックスを取得し

253
00:17:44,965 --> 00:17:47,401
顔の特徴が把握できます

254
00:17:48,435 --> 00:17:53,373
ランドマークのリクエストの
処理が始まると―

255
00:17:53,474 --> 00:17:57,911
顔の検出は
まだであると理解され―

256
00:17:58,579 --> 00:18:01,915
代わりにディテクタ内で
実行されるのです

257
00:17:58,579 --> 00:18:01,915
代わりにディテクタ内で
実行されるのです

258
00:18:02,015 --> 00:18:06,920
ランドマークはディテクタで
検索されます

259
00:18:08,956 --> 00:18:10,724
右側を見てください

260
00:18:12,893 --> 00:18:17,664
オブザベーションオブジェクトの
いくつかの項目です

261
00:18:17,764 --> 00:18:21,268
１つ目は 一意のIDです

262
00:18:21,535 --> 00:18:24,771
２番目は 境界ボックス

263
00:18:24,938 --> 00:18:29,910
最後は顔の特徴を表す
ランドマークです

264
00:18:33,747 --> 00:18:38,619
次は同じユースケースを
明示的順序で見ます

265
00:18:40,621 --> 00:18:44,925
ディテクタを
明示的な順序で作動させます

266
00:18:46,393 --> 00:18:52,199
この４行を実行すると
境界ボックスを取得できます

267
00:18:52,499 --> 00:18:56,870
結果は同じタイプの
オブザベーションで

268
00:18:57,137 --> 00:18:59,239
項目は先ほどと同じです

269
00:18:59,339 --> 00:19:03,644
このプロセスを表す
一意の番号や

270
00:18:59,339 --> 00:19:03,644
このプロセスを表す
一意の番号や

271
00:19:04,011 --> 00:19:09,049
この処理の主な結果である
境界ボックス

272
00:19:09,149 --> 00:19:13,720
そしてランドマークは
nilとなります

273
00:19:14,721 --> 00:19:18,091
次にランドマークの
リクエストを作成し

274
00:19:18,492 --> 00:19:24,698
その結果をオブザベーションの
プロパティにフィードします

275
00:19:25,866 --> 00:19:28,569
次にリクエストハンドラに
処理を依頼し

276
00:19:29,203 --> 00:19:31,038
最後に結果を見ます

277
00:19:31,605 --> 00:19:37,945
同じ画像で実行すると
まったく同じ結果になります

278
00:19:38,612 --> 00:19:40,747
オブザベーションは
どうなるか？

279
00:19:40,948 --> 00:19:43,183
両方のディテクタが

280
00:19:43,517 --> 00:19:49,189
同じタイプを返しても
オブザベーションは変更できません

281
00:19:49,323 --> 00:19:52,993
しかし上書きもしません

282
00:19:53,193 --> 00:19:57,931
２つの項目を
新しいオブジェクトにコピーし

283
00:19:58,298 --> 00:20:01,301
ランドマークを
項目に追加します

284
00:19:58,298 --> 00:20:01,301
ランドマークを
項目に追加します

285
00:20:02,135 --> 00:20:06,573
ほとんどのケースで
UIDが同じです

286
00:20:07,174 --> 00:20:08,041
なぜでしょう？

287
00:20:08,141 --> 00:20:12,579
同じ顔だから
同じ処理ステップなのです

288
00:20:14,147 --> 00:20:16,483
暗黙･明示の使い分け方は？

289
00:20:17,284 --> 00:20:22,256
シンプルなアプリケーションなら
暗黙的がいいでしょう

290
00:20:22,356 --> 00:20:25,959
リクエストを作成するだけで
いいのです

291
00:20:28,595 --> 00:20:32,166
反対に
複雑なアプリケーションなら

292
00:20:32,266 --> 00:20:35,769
顔を検出してから
フィルタリングしましょう

293
00:20:35,903 --> 00:20:41,408
例えば 中央の顔のみに
フォーカスしたい場合は―

294
00:20:41,675 --> 00:20:46,680
そのステップのあと
周辺の顔のランドマークを見ます

295
00:20:47,147 --> 00:20:49,983
この場合は明示的が
いいでしょう

296
00:20:50,517 --> 00:20:55,489
内部でフェイスディテクタを
再稼働させないからです

297
00:21:02,463 --> 00:21:07,267
皆さんのアプリケーションの
パフォーマンス最適化が目標です

298
00:21:07,367 --> 00:21:10,003
次のスライドが重要です

299
00:21:11,905 --> 00:21:13,774
オブジェクトの保存時間は？

300
00:21:16,944 --> 00:21:21,648
イメージリクエストハンドラでは
画像処理の間中 保存しましょう

301
00:21:22,249 --> 00:21:27,421
シンプルですが
それが非常に重要なことです

302
00:21:28,121 --> 00:21:32,125
オブジェクトを
早期にリリースすれば

303
00:21:32,226 --> 00:21:34,495
再びハンドラの作成が必要です

304
00:21:34,595 --> 00:21:38,532
しかしすべての
キャッシュを失っているため

305
00:21:38,632 --> 00:21:42,135
再計算が必要になるのです

306
00:21:43,804 --> 00:21:49,309
一方でリリースが遅すぎると
メモリが断片化し

307
00:21:49,610 --> 00:21:54,982
他の重要なことに
メモリを再利用できなくなります

308
00:21:56,350 --> 00:22:00,621
必要な期間 使用したら
すぐリリースしましょう

309
00:21:56,350 --> 00:22:00,621
必要な期間 使用したら
すぐリリースしましょう

310
00:22:00,721 --> 00:22:04,525
内部にイメージや派生物を
格納しています

311
00:22:06,360 --> 00:22:09,496
シーケンスリクエストハンドラも
同様ですが

312
00:22:09,596 --> 00:22:14,034
リリースが早すぎると
シーケンス全体がダメになります

313
00:22:14,134 --> 00:22:16,470
全キャッシュを失うからです

314
00:22:18,305 --> 00:22:21,041
リクエストと
オブザベーションは？

315
00:22:21,608 --> 00:22:25,345
どちらも非常に軽い
オブジェクトで

316
00:22:25,445 --> 00:22:28,448
キャッシュの必要も
ありません

317
00:22:35,789 --> 00:22:37,391
どこでリクエスト処理を？

318
00:22:39,860 --> 00:22:43,630
Visionではデバイスの
ニューラルネットワークが頼りです

319
00:22:44,464 --> 00:22:49,369
ニューラルネットワークの実行は
通常はCPUよりもGPUの方が高速です

320
00:22:51,772 --> 00:22:54,007
どちらで実行すべきか？

321
00:22:55,676 --> 00:23:01,348
GPUで実行できる場合
まずはそれを試します

322
00:22:55,676 --> 00:23:01,348
GPUで実行できる場合
まずはそれを試します

323
00:23:01,915 --> 00:23:06,420
できなければCPUに
切り替えます

324
00:23:08,021 --> 00:23:09,523
それがデフォルトです

325
00:23:10,958 --> 00:23:15,929
しかしグラフィック表示が多い
アプリケーションなら

326
00:23:16,029 --> 00:23:19,933
GPUはその作業に
とっておきましょう

327
00:23:20,033 --> 00:23:25,339
その場合はCPUを上書きし
trueに設定します

328
00:23:25,439 --> 00:23:28,509
これでCPU上で
直接処理できます

329
00:23:35,182 --> 00:23:38,719
ここまでVisionの
ベーシックな―

330
00:23:38,819 --> 00:23:42,289
インタラクションについて
説明してきました

331
00:23:42,589 --> 00:23:46,693
次はVisionでの
トラッキングについてです

332
00:23:48,829 --> 00:23:49,863
トラッキングとは―

333
00:23:50,931 --> 00:23:55,936
フレームのシーケンス内で
対象のオブジェクトを探すことです

334
00:23:56,036 --> 00:24:01,208
通常は最初のフレームで
オブジェクトを見つけます

335
00:23:56,036 --> 00:24:01,208
通常は最初のフレームで
オブジェクトを見つけます

336
00:24:02,142 --> 00:24:04,244
利用方法は？

337
00:24:04,478 --> 00:24:06,480
いろいろと使えます

338
00:24:06,847 --> 00:24:12,986
注釈付きの
スポーツイベントなど様々です

339
00:24:15,355 --> 00:24:20,260
なぜトラッキングを
使用するのでしょう

340
00:24:20,694 --> 00:24:22,763
いくつかの理由があります

341
00:24:23,096 --> 00:24:28,335
まず 各オブジェクト特定の
トラッカーがあるとは限りません

342
00:24:28,902 --> 00:24:33,674
顔であれば
フェイスディテクタがあります

343
00:24:33,941 --> 00:24:37,578
では鳥のトラッキングは
どうでしょう

344
00:24:37,778 --> 00:24:43,851
そのためのディテクタを
作成しなくてはいけませんが

345
00:24:43,951 --> 00:24:48,655
他の作業があるので
やりたくないですよね

346
00:24:50,424 --> 00:24:52,893
でも顔のトラッキングに

347
00:24:52,993 --> 00:24:54,761
ディテクタを使いますか？

348
00:24:55,095 --> 00:24:57,498
おそらく必要ありません

349
00:24:58,031 --> 00:24:59,333
例をご紹介します

350
00:25:00,500 --> 00:25:04,004
最初のフレームで
ディテクタを稼働します

351
00:25:04,137 --> 00:25:05,439
５つの顔を回収し

352
00:25:06,039 --> 00:25:09,309
２つ目のフレームからも
回収します

353
00:25:09,576 --> 00:25:14,915
両方のフレームの顔が同じだと
なぜ分かるのでしょう？

354
00:25:15,182 --> 00:25:17,951
人が替わっているかも
しれません

355
00:25:19,152 --> 00:25:22,890
そこでオブジェクトを
マッチングするという

356
00:25:22,990 --> 00:25:26,226
完全に別の作業が発生します

357
00:25:27,060 --> 00:25:28,729
しかしトラッカーは

358
00:25:30,330 --> 00:25:32,299
重要な情報を使います

359
00:25:32,399 --> 00:25:37,905
オブジェクトの軌道を把握し
次の動きを予測するのです

360
00:25:39,540 --> 00:25:41,208
顔のトラッキングをして

361
00:25:41,442 --> 00:25:45,946
フレーム中に
単一の顔があるとします

362
00:25:46,046 --> 00:25:47,714
ディテクタを使いますか？

363
00:25:48,248 --> 00:25:50,250
この場合も不要でしょう

364
00:25:56,423 --> 00:26:01,728
トラッカーは通常は軽量の
アルゴリズムですが

365
00:25:56,423 --> 00:26:01,728
トラッカーは通常は軽量の
アルゴリズムですが

366
00:26:01,828 --> 00:26:04,765
ディテクタは
時間がかかります

367
00:26:05,933 --> 00:26:08,035
情報を表示する場合―

368
00:26:08,402 --> 00:26:13,841
トラッカーの方が
スムーズに感じると思います

369
00:26:17,244 --> 00:26:20,948
３つの言葉が大切だと
言いましたね

370
00:26:23,183 --> 00:26:25,319
“何を”“どのように”
“結果”です

371
00:26:25,853 --> 00:26:29,223
トラッキングの
ユースケースではどうでしょう

372
00:26:30,891 --> 00:26:33,727
まずはリクエストです

373
00:26:34,328 --> 00:26:38,031
Visionには
２種類のリクエストがあります

374
00:26:38,131 --> 00:26:42,236
一般的なトラッカーと
長方形のトラッカーです

375
00:26:42,936 --> 00:26:43,771
使い方は？

376
00:26:44,571 --> 00:26:48,308
SequenceRequestHandler
を使います

377
00:26:49,743 --> 00:26:50,510
結果です

378
00:26:51,578 --> 00:26:53,113
このうち２つが重要

379
00:26:53,213 --> 00:26:56,884
検出された
オブザベーションには

380
00:26:56,984 --> 00:26:59,686
境界ボックスがあります

381
00:27:00,254 --> 00:27:02,689
長方形のオブザベーションは

382
00:27:02,956 --> 00:27:07,094
長方形の頂点が
どこにあるか示します

383
00:27:07,861 --> 00:27:11,565
なぜ長方形の頂点が
必要なのでしょう

384
00:27:12,299 --> 00:27:16,770
長方形を描く時には
長方形のオブジェクトが存在します

385
00:27:16,870 --> 00:27:19,907
しかしフレームに投影されると

386
00:27:20,040 --> 00:27:22,342
違う形に見える可能性も

387
00:27:23,477 --> 00:27:25,412
このケースでは

388
00:27:25,512 --> 00:27:30,250
境界ボックスはそれ自体が
長方形ではないのです

389
00:27:33,654 --> 00:27:35,022
デモを見てみましょう

390
00:27:47,301 --> 00:27:52,639
サンプルのアプリケーションは
WWDCのウェブサイトから

391
00:27:52,740 --> 00:27:54,908
ダウンロードできます

392
00:27:55,375 --> 00:27:58,145
ムービーの撮影ができます

393
00:27:59,413 --> 00:28:01,748
フレームに解析します

394
00:27:59,413 --> 00:28:01,748
フレームに解析します

395
00:28:01,982 --> 00:28:07,354
最初のフレームで
オブジェクトを選択します

396
00:28:08,522 --> 00:28:10,023
まずはこちらです

397
00:28:11,692 --> 00:28:15,596
最初にオブジェクトか
長方形を選んで

398
00:28:15,696 --> 00:28:19,700
次に使用するアルゴリズムを
選びます

399
00:28:19,800 --> 00:28:22,302
Visionでは
２種類サポートします

400
00:28:23,136 --> 00:28:27,274
速さと正確性の
どちらかを選べます

401
00:28:28,809 --> 00:28:32,212
今回は速い方を
使いましょう

402
00:28:32,813 --> 00:28:34,081
対象を選択します

403
00:28:35,082 --> 00:28:38,619
赤い傘をさした人物を
トラッキングして

404
00:28:38,719 --> 00:28:41,088
この集団の
トラッキングも試みます

405
00:28:45,826 --> 00:28:46,727
稼働させます

406
00:28:54,635 --> 00:28:59,740
選択したオブジェクトを
うまくトラッキングしています

407
00:29:06,947 --> 00:29:09,616
もっと複雑な例です

408
00:29:10,617 --> 00:29:13,687
ウェイクボーダーの男性です

409
00:29:14,721 --> 00:29:16,924
今度は正確性を選びます

410
00:29:17,858 --> 00:29:19,459
対象を選択して

411
00:29:23,330 --> 00:29:24,698
稼働させます

412
00:29:30,370 --> 00:29:34,641
オブジェクトの様子は
変わっていきますが

413
00:29:34,741 --> 00:29:38,979
形や配置や色が変わっても
トラッキングできます

414
00:29:39,079 --> 00:29:40,514
優れた機能です

415
00:29:40,914 --> 00:29:45,419
(拍手)

416
00:29:47,788 --> 00:29:52,793
次は実際に実行されている
様子をお見せします

417
00:30:01,101 --> 00:30:04,705
Xcodeを稼働し
iPhoneをつないで―

418
00:30:04,805 --> 00:30:08,041
先ほどのアプリケーションを
使用します

419
00:30:09,376 --> 00:30:11,145
デバッガで稼働させて

420
00:30:16,583 --> 00:30:18,018
対象を選択します

421
00:30:19,253 --> 00:30:22,756
今回の目的は
シーケンスを見ることです

422
00:30:23,290 --> 00:30:24,525
稼働させます

423
00:30:27,728 --> 00:30:31,398
ここで
ブレークポイントを設定して

424
00:30:31,498 --> 00:30:34,368
トラッキング機能を
実行します

425
00:30:34,668 --> 00:30:37,137
シーケンスを
実行する機能です

426
00:30:38,739 --> 00:30:40,240
見てみましょう

427
00:30:40,340 --> 00:30:43,577
まずビデオリーダーを作成します

428
00:30:43,977 --> 00:30:49,082
対象を選択する最初のフレームを
削除します

429
00:30:50,284 --> 00:30:51,985
キャンセルのフラグです

430
00:30:52,719 --> 00:30:56,290
次にinputObservationを
初期化します

431
00:30:56,390 --> 00:30:58,659
先ほどお見せしましたね

432
00:31:01,295 --> 00:31:05,833
そして結果を表示可能に
するための記帳は

433
00:31:06,433 --> 00:31:09,770
TrackedPolyRectに保管されます

434
00:31:10,971 --> 00:31:13,874
スイッチを稼働します

435
00:31:13,974 --> 00:31:18,812
タイプは
ユーザインターフェイス由来です

436
00:31:20,047 --> 00:31:22,416
２つ選択しました

437
00:31:23,317 --> 00:31:28,455
ユーザインターフェイス
からの情報です

438
00:31:31,859 --> 00:31:33,060
この２つです

439
00:31:33,360 --> 00:31:36,230
このループが２度稼働します

440
00:31:36,330 --> 00:31:42,269
これがスライドに表示されている
inputObservationを初期化します

441
00:31:43,403 --> 00:31:45,205
境界ボックスを渡すのです

442
00:31:46,206 --> 00:31:49,843
そして
記帳構造を初期化します

443
00:31:50,010 --> 00:31:50,944
稼働させます

444
00:31:58,385 --> 00:32:00,487
見てみましょう

445
00:31:58,385 --> 00:32:00,487
見てみましょう

446
00:32:08,095 --> 00:32:12,166
重要な項目がいくつかあり
これは一意のIDです

447
00:32:12,800 --> 00:32:15,836
境界ボックスは
正規化しています

448
00:32:17,971 --> 00:32:20,941
長方形として使わないため

449
00:32:21,108 --> 00:32:24,078
このブレークポイントをつけます

450
00:32:26,313 --> 00:32:29,049
これがポイントとなります

451
00:32:30,851 --> 00:32:32,453
フレームカウンタです

452
00:32:33,854 --> 00:32:35,856
失敗するとフラグが出ます

453
00:32:36,523 --> 00:32:39,259
トラッキングを開始します

454
00:32:39,393 --> 00:32:45,332
この無限ループから
抜けるにはキャンセルするか

455
00:32:45,432 --> 00:32:47,267
ムービーを終了させます

456
00:32:51,271 --> 00:32:54,041
グラフィカルユーザに

457
00:32:54,875 --> 00:33:00,347
情報を維持するため
長方形構造を初期化します

458
00:32:54,875 --> 00:33:00,347
情報を維持するため
長方形構造を初期化します

459
00:33:00,647 --> 00:33:06,053
そしてオブザベーションの
ループを開始します

460
00:33:06,320 --> 00:33:08,956
TrackObjectRequestを作成します

461
00:33:14,995 --> 00:33:19,900
リクエストを進めて
すべてを収集します

462
00:33:22,402 --> 00:33:26,974
ループを切断し
処理の準備ができました

463
00:33:27,574 --> 00:33:32,713
実行機能でリクエストの
収集が受理されます

464
00:33:33,080 --> 00:33:36,683
単一のリクエストを
使用しただけで

465
00:33:36,783 --> 00:33:40,721
同時に２つのリクエストを
トラッキングします

466
00:33:41,388 --> 00:33:42,623
実行します

467
00:33:44,625 --> 00:33:49,196
リクエストを実行したので
結果を見てみます

468
00:33:49,296 --> 00:33:52,065
それぞれの
プロパティで見ます

469
00:33:54,968 --> 00:33:58,739
プロパティでは最初の
オブジェクトを取得します

470
00:33:58,839 --> 00:34:02,943
単一のものが
オブザベーションとしてあります

471
00:33:58,839 --> 00:34:02,943
単一のものが
オブザベーションとしてあります

472
00:34:03,677 --> 00:34:08,482
オブザベーションの
信頼度のプロパティを見て

473
00:34:08,748 --> 00:34:11,284
任意のしきい値を0.5にします

474
00:34:12,018 --> 00:34:17,056
しきい値より上であれば
境界ボックスを実線で描き

475
00:34:17,157 --> 00:34:20,327
下であれば点線で描きます

476
00:34:20,427 --> 00:34:23,530
不具合があるか分かります

477
00:34:26,333 --> 00:34:28,735
残りはシンプルな記帳です

478
00:34:29,503 --> 00:34:31,338
長方形の構造を追加し

479
00:34:32,039 --> 00:34:36,577
当該のループから
オブザベーションを取ります

480
00:34:36,677 --> 00:34:39,913
そして 次のループに
割り当てます

481
00:34:43,784 --> 00:34:45,452
これは２度目です

482
00:34:46,018 --> 00:34:48,088
ブレークポイントに行きます

483
00:34:49,156 --> 00:34:50,724
フレームを表示し―

484
00:34:51,824 --> 00:34:56,029
フレームレートに合わせて
スリープにします

485
00:34:56,663 --> 00:35:01,335
すると トラッキングの
２つ目のループに来ています

486
00:34:56,663 --> 00:35:01,335
すると トラッキングの
２つ目のループに来ています

487
00:35:03,971 --> 00:35:05,873
スライドに戻りましょう

488
00:35:10,911 --> 00:35:16,283
(拍手)

489
00:35:18,852 --> 00:35:22,122
重要な点を復習しましょう

490
00:35:23,056 --> 00:35:27,027
まずはオブジェクトの
初期化の方法です

491
00:35:27,961 --> 00:35:32,399
自動で境界ボックスを
取り出すのが

492
00:35:32,499 --> 00:35:34,201
１つ目です

493
00:35:34,635 --> 00:35:37,905
２つ目は手動で行う方法です

494
00:35:53,120 --> 00:35:58,659
単一のトラッキングリクエストを
オブジェクトごとに使用しました

495
00:35:58,759 --> 00:36:00,861
関係性は１対１です

496
00:35:58,759 --> 00:36:00,861
関係性は１対１です

497
00:36:03,597 --> 00:36:05,566
トラッカーは２種類あります

498
00:36:05,666 --> 00:36:09,837
一般的なトラッカーと
長方形のトラッカーです

499
00:36:12,573 --> 00:36:16,176
それぞれに２つの
アルゴリズムがあります

500
00:36:16,276 --> 00:36:19,179
速さと正確性ですが
この２つは―

501
00:36:19,780 --> 00:36:21,949
交換条件なのです

502
00:36:23,784 --> 00:36:27,454
結果が信用できるか否かを
判断するために

503
00:36:27,888 --> 00:36:31,058
信頼度のプロパティを
お見せしました

504
00:36:34,395 --> 00:36:37,898
Visionでの
トラッキングの限界は？

505
00:36:41,235 --> 00:36:43,136
まずはトラッカーの数です

506
00:36:45,372 --> 00:36:47,975
同時に
トラッキングできる数は？

507
00:36:48,375 --> 00:36:53,781
各タイプで16の
トラッカーの設定が限界です

508
00:36:53,881 --> 00:36:59,486
一般的なもので16と
長方形で16ということです

509
00:37:00,621 --> 00:37:03,090
それ以上はエラーが出ます

510
00:37:03,857 --> 00:37:09,163
その場合 いくつかトラッカーを
リリースしてください

511
00:37:09,396 --> 00:37:10,430
やり方は？

512
00:37:12,432 --> 00:37:16,036
最後のフレームの
プロパティを設定し

513
00:37:16,270 --> 00:37:19,940
リクエストハンドラに
フィードさせます

514
00:37:20,207 --> 00:37:25,579
これで関連するトラッカーを
リリースすべきと認識します

515
00:37:26,213 --> 00:37:29,249
またはリクエストに
関わる―

516
00:37:29,349 --> 00:37:33,987
すべてのトラッカーを
リリースしてください

517
00:37:38,926 --> 00:37:43,931
トラッキングシーケンスの
実行後にはどんな課題が？

518
00:37:44,365 --> 00:37:49,770
トラッキングシーケンスでは
対象の様子が変化します

519
00:37:49,937 --> 00:37:53,140
色や配置が変わることは

520
00:37:53,340 --> 00:37:55,976
アルゴリズムにとって
課題です

521
00:37:56,477 --> 00:37:57,878
どうすればいいか？

522
00:37:58,479 --> 00:38:02,449
万能の解決方法はありません

523
00:37:58,479 --> 00:38:02,449
万能の解決方法はありません

524
00:38:02,549 --> 00:38:07,521
しかし速さと
正確性を試してみて

525
00:38:07,854 --> 00:38:11,658
うまくいく方法を
探ってください

526
00:38:15,128 --> 00:38:17,498
境界ボックスを選択するなら

527
00:38:17,798 --> 00:38:21,235
突出したオブジェクトを
見つけます

528
00:38:22,836 --> 00:38:24,538
信頼度のしきい値は？

529
00:38:25,239 --> 00:38:27,041
答えは１つではなく

530
00:38:27,141 --> 00:38:33,180
それぞれのケースがしかるべき
しきい値で機能します

531
00:38:34,848 --> 00:38:36,950
テクニックをお教えします

532
00:38:37,051 --> 00:38:41,321
1000フレームのトラッキング
シーケンスがあるとします

533
00:38:42,156 --> 00:38:44,358
それを開始すると

534
00:38:44,458 --> 00:38:49,096
選択したオブジェクトは
逸脱を始めます

535
00:38:49,196 --> 00:38:53,567
そのまま続けると
すべてが変わってしまいます

536
00:38:54,234 --> 00:38:59,473
そこで50フレームくらいの
サブシーケンスに分けます

537
00:38:59,573 --> 00:39:03,143
ディテクタを稼働して
50フレームでトラッキングし―

538
00:38:59,573 --> 00:39:03,143
ディテクタを稼働して
50フレームでトラッキングし―

539
00:39:03,243 --> 00:39:07,948
ディテクタの再稼働を
50フレームごとに繰り返します

540
00:39:08,148 --> 00:39:13,120
単一のオブジェクトの
トラッキングに見えるでしょう

541
00:39:13,620 --> 00:39:16,457
しかしその内部では

542
00:39:16,557 --> 00:39:21,662
小さなシーケンスを
トラッキングしているのです

543
00:39:27,201 --> 00:39:29,069
要約します

544
00:39:30,204 --> 00:39:35,042
最初に Visionを使う目的や
フレームワーク

545
00:39:35,208 --> 00:39:39,179
プライバシーについて
お話ししました

546
00:39:41,381 --> 00:39:47,521
次に 方向に左右されない最新の
フェイスディテクタを紹介しました

547
00:39:48,021 --> 00:39:49,890
修正についてもです

548
00:39:51,191 --> 00:39:54,261
Vision APIとの
インタラクションや

549
00:39:54,461 --> 00:39:58,765
リクエストやオブザベーション
などについてお話ししました

550
00:39:59,867 --> 00:40:03,771
最後はトラッキングを
実行する方法です

551
00:39:59,867 --> 00:40:03,771
最後はトラッキングを
実行する方法です

552
00:40:05,606 --> 00:40:10,244
詳細はこちらの
ウェブサイトをご覧ください

553
00:40:10,477 --> 00:40:14,415
次のセッションへの参加も
お勧めします

554
00:40:14,515 --> 00:40:17,684
VisionとCoreMLの
併用についてご説明します

555
00:40:17,784 --> 00:40:20,821
独自のモデルには
重要となります

556
00:40:21,121 --> 00:40:26,627
さらにフレームワークの
詳細もカバーする予定です

557
00:40:27,561 --> 00:40:30,464
明日はVision Labです

558
00:40:31,064 --> 00:40:33,801
引き続き WWDCを
お楽しみください

559
00:40:33,901 --> 00:40:38,338
(拍手)