
1
00:00:06,974 --> 00:00:14,948
(音楽)

2
00:00:21,121 --> 00:00:27,027
(拍手)

3
00:00:29,730 --> 00:00:35,002
Metal for Accelerating Machine
Learningのセッションへようこそ

4
00:00:35,435 --> 00:00:39,640
GPUソフトウェアチームの
アナ･チコノバです

5
00:00:42,843 --> 00:00:46,213
Metalをベースとする
MPSフレームワークは

6
00:00:46,446 --> 00:00:48,916
iOSとmacOSに最適化した―

7
00:00:49,016 --> 00:00:52,152
GPUで加速化したプリミティブを
提供します

8
00:00:52,753 --> 00:00:57,858
画像処理や機械学習などの
プリミティブです

9
00:00:58,492 --> 00:01:04,631
過去のWWDCで “推論”に
関するセッションがありましたが

10
00:00:58,492 --> 00:01:04,631
過去のWWDCで “推論”に
関するセッションがありましたが

11
00:01:06,300 --> 00:01:11,438
今年はiOSとmacOS上の
“訓練”に関する話もします

12
00:01:11,872 --> 00:01:15,676
(拍手)

13
00:01:15,776 --> 00:01:16,610
どうも

14
00:01:18,712 --> 00:01:22,449
レイトレーシングの高速化の
サポートについても

15
00:01:22,549 --> 00:01:26,420
今週前半に
セッションが行われました

16
00:01:26,520 --> 00:01:29,389
Metal for Ray
Tracing Accelerationです

17
00:01:29,690 --> 00:01:33,393
ビデオはオンラインで
まもなく公開されます

18
00:01:34,261 --> 00:01:39,166
ここでは機械学習の
主に訓練について話します

19
00:01:42,069 --> 00:01:44,204
訓練と推論は関係します

20
00:01:44,571 --> 00:01:49,810
ディープラーニングアルゴリズムの
第１フェーズは訓練です

21
00:01:50,310 --> 00:01:53,447
例を使って説明しましょう

22
00:01:53,547 --> 00:01:58,719
猫や犬などのクラスに
画像を分類する例です

23
00:01:59,853 --> 00:02:03,023
猫を認識するよう
訓練するには

24
00:01:59,853 --> 00:02:03,023
猫を認識するよう
訓練するには

25
00:02:03,123 --> 00:02:06,760
ラベル付けした猫の画像を
大量に与えます

26
00:02:06,960 --> 00:02:12,332
認識させたい他の動物についても
同様の処理をします

27
00:02:13,967 --> 00:02:18,705
訓練はコストと時間がかかる
反復プロセスです

28
00:02:19,306 --> 00:02:22,142
訓練の結果は
学習済みパラメータとなり―

29
00:02:24,611 --> 00:02:28,348
次の推論フェーズに
必要になります

30
00:02:28,649 --> 00:02:31,585
初めて見る画像を
分類するには

31
00:02:31,685 --> 00:02:37,157
“これは猫だ”という学習済み
パラメータが元になるのです

32
00:02:38,192 --> 00:02:43,130
訓練と推論の両方に
GPUによる加速化を提供します

33
00:02:45,732 --> 00:02:51,405
その前に 今年追加された
CNN推論の話をしましょう

34
00:02:51,872 --> 00:02:54,842
畳み込みと転置畳み込みの
プリミティブに

35
00:02:54,942 --> 00:02:58,412
FP16の蓄積を
サポートする機能は

36
00:02:58,846 --> 00:03:03,517
Apple A11 Bionic GPUで
利用できます

37
00:02:58,846 --> 00:03:03,517
Apple A11 Bionic GPUで
利用できます

38
00:03:04,284 --> 00:03:08,455
FP16の蓄積を
推論に使用するのは

39
00:03:08,555 --> 00:03:14,494
ニューラルネットワークでは
精度の点で十分です

40
00:03:15,495 --> 00:03:20,434
FP16は精度とパワーの面で
大きなメリットがあるので

41
00:03:20,534 --> 00:03:24,338
ぜひ 推論作業に
活用してください

42
00:03:25,572 --> 00:03:30,878
これは畳み込みのプリミティブに
FP16の蓄積を利用する例です

43
00:03:30,978 --> 00:03:34,314
accumulatorPrecisionOptionを
設定するだけです

44
00:03:36,617 --> 00:03:42,923
今回のメインテーマは
ニューラルネットワークの訓練です

45
00:03:43,023 --> 00:03:46,059
まず CNNから始めましょう

46
00:03:48,762 --> 00:03:52,032
手書き数字認識
ネットワークです

47
00:03:53,133 --> 00:03:56,403
手書き画像が入力されると

48
00:03:56,803 --> 00:04:00,774
０～９のうち
どれか１つがアサインされます

49
00:03:56,803 --> 00:04:00,774
０～９のうち
どれか１つがアサインされます

50
00:04:01,542 --> 00:04:06,647
例では数字７の画像が
正しく分類されています

51
00:04:09,283 --> 00:04:13,320
推論のための
訓練済みパラメータが

52
00:04:13,921 --> 00:04:19,526
畳み込みと完全に接続された
プリミティブに重みを加えます

53
00:04:20,293 --> 00:04:23,597
目標は
訓練済みパラメータを計算し

54
00:04:23,697 --> 00:04:28,735
推論中に出力を
修正することです

55
00:04:30,304 --> 00:04:34,775
重みは最初からないので
計算が必要なため

56
00:04:34,942 --> 00:04:39,813
まず 小さな ランダムな数で
重みを初期化します

57
00:04:39,913 --> 00:04:41,882
これで準備完了です

58
00:04:41,982 --> 00:04:45,552
では 訓練プロセスの
全ステップを見ましょう

59
00:04:47,988 --> 00:04:53,460
訓練は反復プロセスです
４つのステップからなります

60
00:04:53,894 --> 00:04:55,762
最初がフォワードパス

61
00:04:55,863 --> 00:05:00,601
入力をネットワークに渡し
出力を作ります

62
00:04:55,863 --> 00:05:00,601
入力をネットワークに渡し
出力を作ります

63
00:05:00,934 --> 00:05:02,836
推論に似ていますね

64
00:05:04,137 --> 00:05:06,206
次に損失を計算します

65
00:05:06,473 --> 00:05:11,411
損失とは出力と
正解データの差です

66
00:05:13,180 --> 00:05:16,717
訓練アルゴリズムの目的は
損失の最小化です

67
00:05:18,685 --> 00:05:21,054
次のステップは勾配のパス

68
00:05:21,388 --> 00:05:25,859
出力と正解の差を
ネットワークに戻し

69
00:05:25,959 --> 00:05:29,229
重みを更新することです

70
00:05:29,830 --> 00:05:35,135
訓練の継続でネットワークは
より訓練されるのです

71
00:05:35,235 --> 00:05:39,139
入力のマッピングで
出力を修正でき

72
00:05:39,673 --> 00:05:41,909
損失の最小化を促進します

73
00:05:43,177 --> 00:05:47,981
概要は以上です　次は各ステップを
詳細に見ていきます

74
00:05:50,317 --> 00:05:55,355
フォワードパスは
出力計算のための順伝播です

75
00:05:56,023 --> 00:06:00,961
訓練当初は ネットワークが
うまく機能しません

76
00:05:56,023 --> 00:06:00,961
訓練当初は ネットワークが
うまく機能しません

77
00:06:01,728 --> 00:06:05,365
なぜ間違った結果に
なるのでしょう

78
00:06:05,499 --> 00:06:09,570
それは想定内ですが
重みを初期化したためで

79
00:06:09,670 --> 00:06:12,272
訓練がまだだからです

80
00:06:13,807 --> 00:06:20,013
そこで ネットワークの成績を
数値化する重みが必要になります

81
00:06:20,113 --> 00:06:23,784
この情報を使い
重みを改善することで

82
00:06:23,884 --> 00:06:28,455
訓練を続ければ
良い結果が出るはずです

83
00:06:30,123 --> 00:06:34,428
そのためには まず
正解を知らねばなりません

84
00:06:34,795 --> 00:06:37,931
今から 正解データを
ラベルと呼びます

85
00:06:38,031 --> 00:06:41,535
入力画像とともに入れる
ネットワークへの入力のことです

86
00:06:42,202 --> 00:06:44,371
ここでは
10の値のベクトルで

87
00:06:44,471 --> 00:06:49,243
正解の７に１
他は０をアサインします

88
00:06:51,512 --> 00:06:56,016
各クラスにつき
10分の１の確率で出力します

89
00:06:56,383 --> 00:06:58,919
ご覧のように訓練の最初は

90
00:06:59,019 --> 00:07:03,323
ネットワークの正解が
非常に低いです

91
00:06:59,019 --> 00:07:03,323
ネットワークの正解が
非常に低いです

92
00:07:03,490 --> 00:07:07,261
９に最高確率を
アサインします

93
00:07:07,361 --> 00:07:10,097
答えに９を出したからです

94
00:07:11,331 --> 00:07:15,969
この情報を全部
損失プリミティブに渡します

95
00:07:18,572 --> 00:07:20,674
先ほど述べたように

96
00:07:21,341 --> 00:07:26,680
損失は出力と
正解データの差を測ります

97
00:07:27,381 --> 00:07:30,684
アルゴリズムの目的は
損失の最小化です

98
00:07:32,219 --> 00:07:34,788
後半のグラフも使います

99
00:07:36,456 --> 00:07:40,294
勾配プリミティブは
フォワードプリミティブに

100
00:07:40,394 --> 00:07:42,529
対応しています

101
00:07:42,696 --> 00:07:47,901
勾配プリミティブは
重みの更新に必要です

102
00:07:49,770 --> 00:07:54,274
損失プリミティブは
最初の勾配を計算します

103
00:07:54,374 --> 00:07:58,078
これは入力に関する
損失関数の派生物です

104
00:07:58,178 --> 00:08:03,884
そして この勾配を
ネットワークを通じ逆伝播します

105
00:07:58,178 --> 00:08:03,884
そして この勾配を
ネットワークを通じ逆伝播します

106
00:08:03,984 --> 00:08:09,323
最初の勾配プリミティブが
逆向きに送られるのです

107
00:08:09,423 --> 00:08:13,126
ここでは
SoftMax勾配プリミティブです

108
00:08:13,961 --> 00:08:19,366
連鎖率を使うと
勾配の逆伝播が可能になります

109
00:08:20,400 --> 00:08:24,104
勾配を計算し
重みを更新します

110
00:08:24,204 --> 00:08:29,510
各反復で重みに適用する
微小なデルタを計算します

111
00:08:31,245 --> 00:08:35,414
更新された重みは
次の訓練反復に使い

112
00:08:35,849 --> 00:08:39,986
損失値が
低くなるのが理想です

113
00:08:43,357 --> 00:08:45,993
実際の訓練状況では

114
00:08:46,226 --> 00:08:48,862
単一画像ではなく

115
00:08:48,962 --> 00:08:52,132
画像のグループまたは
バッチを使います

116
00:08:52,232 --> 00:08:55,435
例えば
32または64のバッチです

117
00:08:55,802 --> 00:09:00,474
損失計算には対応する
ラベルのバッチが必要です

118
00:08:55,802 --> 00:09:00,474
損失計算には対応する
ラベルのバッチが必要です

119
00:09:00,574 --> 00:09:03,143
この場合のラベルのバッチは

120
00:09:03,243 --> 00:09:06,780
１が正しいクラス
他が０となります

121
00:09:09,416 --> 00:09:11,084
訓練で使うのは

122
00:09:11,185 --> 00:09:15,789
異なる画像のバッチと
対応するラベルのバッチです

123
00:09:15,956 --> 00:09:18,859
訓練反復を実行しましょう

124
00:09:21,361 --> 00:09:26,133
最初の画像のバッチに対し
フォワードパス 損失計算

125
00:09:26,233 --> 00:09:30,204
勾配のパス
重み更新を行います

126
00:09:30,504 --> 00:09:34,041
２つ目のバッチの
プロセスも同じです

127
00:09:34,141 --> 00:09:38,979
フォワードパス 損失計算
勾配のパス 重み更新です

128
00:09:40,013 --> 00:09:46,186
訓練の反復を続け
ネットワークの損失を減少させ

129
00:09:46,587 --> 00:09:49,356
精度を向上させます

130
00:09:49,490 --> 00:09:50,824
訓練を続けます

131
00:09:50,924 --> 00:09:53,994
損失が
特定のしきい値を下回り

132
00:09:54,094 --> 00:09:57,931
ネットワーク精度が
希望水準になれば

133
00:09:58,665 --> 00:10:00,667
訓練は十分です

134
00:09:58,665 --> 00:10:00,667
訓練は十分です

135
00:10:00,767 --> 00:10:04,605
計算した訓練済みパラメータを
推論に使えます

136
00:10:04,738 --> 00:10:08,976
次は MPSフレームワークを使い

137
00:10:09,076 --> 00:10:11,678
ニューラルネットワークを
訓練します

138
00:10:11,879 --> 00:10:15,849
グラフの抽象化を利用すれば
ネットワークは

139
00:10:15,949 --> 00:10:19,520
MPSでは
グラフとして描けます

140
00:10:20,821 --> 00:10:22,890
まず 訓練グラフを作成し

141
00:10:24,391 --> 00:10:29,229
入力データを準備し 重みを指定
グラフを実行します

142
00:10:29,329 --> 00:10:35,002
フォワードパス 損失計算
勾配のパス 重み更新を行います

143
00:10:35,802 --> 00:10:41,074
訓練は反復プロセスで
多数の反復が必要ですが

144
00:10:41,174 --> 00:10:43,977
やめる時期を
知る必要もあります

145
00:10:44,077 --> 00:10:47,381
では 各トピックの
詳細を見ましょう

146
00:10:47,681 --> 00:10:50,717
訓練グラフの作成からです

147
00:10:52,619 --> 00:10:54,054
繰り返しますが

148
00:10:54,154 --> 00:10:56,957
MPSでは ニューラルネットワーク
グラフAPIを使い

149
00:10:57,057 --> 00:10:58,625
ネットワークを描けます

150
00:10:59,059 --> 00:11:01,328
これは　手入力した―

151
00:10:59,059 --> 00:11:01,328
これは　手入力した―

152
00:11:01,428 --> 00:11:04,298
値認識のネットワークを
視覚化したものです

153
00:11:04,531 --> 00:11:09,403
中に画像ノードが見えます
小さな白いノードです

154
00:11:10,737 --> 00:11:16,910
画像ノードが記述するのは
入力 出力 中間結果です

155
00:11:18,745 --> 00:11:22,316
オペレーション間を
どうデータが動いたか記述します

156
00:11:22,683 --> 00:11:26,553
畳み込みやプーリングなど
データのオペレーションは

157
00:11:26,954 --> 00:11:30,257
フィルタノードで
記述されます

158
00:11:30,791 --> 00:11:34,795
一般的なニューラルネットワークの
作成に必要な全ノードを

159
00:11:34,895 --> 00:11:36,296
サポートしています

160
00:11:37,130 --> 00:11:41,068
ニューラルネットワーク
グラフAPIは簡単です

161
00:11:41,602 --> 00:11:48,408
これを使ったMPSImageNodeの
作成例を見ましょう

162
00:11:48,575 --> 00:11:52,779
これがグラフAPIを使い
畳み込みノードを作成した例です

163
00:11:53,313 --> 00:11:57,918
各フォワードノードに対する
訓練用勾配ノードを

164
00:11:58,018 --> 00:11:59,520
サポートしています

165
00:11:59,620 --> 00:12:03,957
勾配ノード作成の
コードは１行です

166
00:11:59,620 --> 00:12:03,957
勾配ノード作成の
コードは１行です

167
00:12:04,057 --> 00:12:08,228
これが畳み込みノードから
勾配畳み込みノードを

168
00:12:08,328 --> 00:12:09,897
作成する例です

169
00:12:12,966 --> 00:12:14,968
次はグラフを構築します

170
00:12:16,069 --> 00:12:18,205
これは小さいネットワークで

171
00:12:18,305 --> 00:12:21,141
畳み込みノード
プーリングノード

172
00:12:21,241 --> 00:12:23,277
別の畳み込みノードが
続きます

173
00:12:23,744 --> 00:12:29,249
これらのノードをグラフに
接続するのはとても簡単です

174
00:12:29,449 --> 00:12:33,587
あるノードの結果画像を取り

175
00:12:33,687 --> 00:12:38,091
ソース画像として
次のノードに渡します

176
00:12:38,859 --> 00:12:41,828
これでグラフが
結合されました

177
00:12:42,696 --> 00:12:44,932
次は訓練グラフを作ります

178
00:12:45,666 --> 00:12:48,769
まず グラフに損失ノードを追加

179
00:12:49,970 --> 00:12:51,772
勾配ノードもです

180
00:12:51,972 --> 00:12:56,009
これでフォワードノードに
対応する勾配ノードを

181
00:12:56,109 --> 00:12:58,145
１行のコードで作れます

182
00:12:58,245 --> 00:13:02,783
前と同じようにつなげば
訓練グラフの完成です

183
00:12:58,245 --> 00:13:02,783
前と同じようにつなげば
訓練グラフの完成です

184
00:13:05,686 --> 00:13:10,724
ご覧のようにグラフAPIは
使い方が簡単です

185
00:13:11,525 --> 00:13:13,093
グラフは自動で

186
00:13:13,193 --> 00:13:18,398
中間結果や出力画像まで
管理してくれます

187
00:13:19,099 --> 00:13:23,403
また中間画像に
メモリをエイリアスし

188
00:13:23,504 --> 00:13:27,975
Metalヒープで
メモリフットプリントを削減します

189
00:13:28,775 --> 00:13:34,515
グラフのノードを
融合することもできます

190
00:13:34,615 --> 00:13:39,620
不要なノードをカットするなど
最適化も可能です

191
00:13:40,254 --> 00:13:43,023
そして グラフは
自動でパディングと

192
00:13:43,123 --> 00:13:46,927
ステートオブジェクトの
管理もします

193
00:13:47,961 --> 00:13:50,330
ぜひ グラフAPIを
活用してください

194
00:13:54,768 --> 00:13:57,304
訓練グラフを作った後は

195
00:13:57,404 --> 00:14:01,608
グラフに渡す入力を
見ていきましょう

196
00:13:57,404 --> 00:14:01,608
グラフに渡す入力を
見ていきましょう

197
00:14:02,442 --> 00:14:07,548
まず GPUにグラフの
エンコードを呼び出します

198
00:14:08,849 --> 00:14:12,920
訓練では１枚ずつ
画像を送ることはなく

199
00:14:13,020 --> 00:14:16,323
画像のグループかバッチを
使います

200
00:14:16,423 --> 00:14:19,893
グラフへの入力は
画像のバッチなので―

201
00:14:20,761 --> 00:14:23,564
画像の各バッチには

202
00:14:23,664 --> 00:14:27,701
損失計算のため
対応するラベルが必要です

203
00:14:29,670 --> 00:14:34,007
ラベルはグラフに
ステートとして渡され

204
00:14:34,141 --> 00:14:38,312
エンコードのコールが
ステートを受け入れます

205
00:14:38,645 --> 00:14:41,682
バッチとステートとは
何でしょうか

206
00:14:41,782 --> 00:14:43,884
まずバッチから説明します

207
00:14:44,418 --> 00:14:48,021
バッチとは画像や
ステートの配列です

208
00:14:48,121 --> 00:14:51,458
今年から訓練のサポートに
加えました

209
00:14:51,959 --> 00:14:57,965
新しい２つのMPSタイプは
MPSImageBatchとMPSStateBatchです

210
00:14:58,432 --> 00:15:02,970
今回はAPIを使って既存の
Metal Textureから

211
00:14:58,432 --> 00:15:02,970
今回はAPIを使って既存の
Metal Textureから

212
00:15:03,971 --> 00:15:06,974
単一画像を作成します

213
00:15:08,175 --> 00:15:12,613
APIで画像のバッチを作成し
バッチに新しい画像を

214
00:15:12,713 --> 00:15:16,450
グラフに渡せるよう
アペンドした例です

215
00:15:18,385 --> 00:15:20,654
次は
ステートオブジェクトです

216
00:15:21,121 --> 00:15:24,792
MPSのステートは不透明な
データの入れ物で

217
00:15:25,659 --> 00:15:27,761
訓練でよく使われます

218
00:15:27,861 --> 00:15:32,533
フォワードノードの
ステートを取り込み

219
00:15:32,766 --> 00:15:36,370
これが後で
勾配ノードに使われます

220
00:15:36,937 --> 00:15:39,506
全てグラフが行うので

221
00:15:39,606 --> 00:15:43,076
デベロッパたちは
ステートの心配は不要です

222
00:15:43,177 --> 00:15:46,980
でも仕組みを知るのは
いいことですよね

223
00:15:48,949 --> 00:15:52,186
手書き数字認識
ネットワークに戻り

224
00:15:53,153 --> 00:15:57,558
ドロップアウト勾配ノードと
ドロップアウトを見ましょう

225
00:16:00,661 --> 00:16:06,633
フォワードドロップアウトノードは
入力値を０にします

226
00:16:07,234 --> 00:16:09,369
ドロップアウト
ステートオブジェクトは

227
00:16:09,469 --> 00:16:12,906
フォワードドロップアウトの
情報を取り込み

228
00:16:13,607 --> 00:16:16,643
これがドロップアウト
勾配ノードに使われます

229
00:16:16,877 --> 00:16:23,617
フォワードのゼロアウト同様
同じ場所で入力勾配の値を

230
00:16:23,717 --> 00:16:26,019
ゼロにするためです

231
00:16:28,956 --> 00:16:33,227
ステートはグラフが
管理するので心配無用ですが

232
00:16:33,760 --> 00:16:38,265
損失計算のラベルは
ステートとして渡され

233
00:16:38,966 --> 00:16:41,201
ユーザ入力が必要です

234
00:16:41,301 --> 00:16:43,770
正解データとなるからです

235
00:16:43,904 --> 00:16:47,040
損失計算の
ラベルのバッチを作り

236
00:16:47,141 --> 00:16:49,543
入力としてグラフに渡します

237
00:16:50,043 --> 00:16:55,015
損失計算の単一ラベルを
作成する例はこれです

238
00:16:55,115 --> 00:17:01,121
損失データの記述子はメモリの中の
レベルデータの配置を記述します

239
00:16:55,115 --> 00:17:01,121
損失データの記述子はメモリの中の
レベルデータの配置を記述します

240
00:17:01,688 --> 00:17:06,660
次に この記述子でMPSCNNLossLabel
オブジェクトを作ります

241
00:17:08,262 --> 00:17:13,133
訓練用にバッチを作り
グラフ実行が終わると

242
00:17:13,333 --> 00:17:18,839
ラベルのバッチは
画像ごとの損失値を含みます

243
00:17:18,939 --> 00:17:24,377
この値やバッチ中の単一値は
計算し調べることができます

244
00:17:27,647 --> 00:17:32,486
訓練グラフとグラフへの
入力について話しました

245
00:17:32,586 --> 00:17:36,723
次は グラフノードへの
重みの付与です

246
00:17:38,892 --> 00:17:42,463
完全結合の畳み込みに
重みを与えるには

247
00:17:42,629 --> 00:17:46,800
バッチとインスタンスの
ノーマライズノードで

248
00:17:46,900 --> 00:17:49,369
Data Source Providerの
プロトコルを使います

249
00:17:50,838 --> 00:17:55,409
これを使った
畳み込みノードの作成例です

250
00:17:56,043 --> 00:18:00,147
プロトコルに合致する
クラスを実装します

251
00:17:56,043 --> 00:18:00,147
プロトコルに合致する
クラスを実装します

252
00:18:00,247 --> 00:18:02,449
MyWeightsと呼びますね

253
00:18:04,618 --> 00:18:08,455
データソースプロバイダは
非常に有用です

254
00:18:08,555 --> 00:18:12,826
例えば ネットワークに
大量の畳み込みノードがあり

255
00:18:13,160 --> 00:18:16,730
重みの全体サイズが
大きい時があります

256
00:18:16,830 --> 00:18:22,336
そんな時は 一度に重みを
メモリに入れたくありません

257
00:18:22,636 --> 00:18:26,907
メモリフットプリントは
低く抑えたいのです

258
00:18:27,374 --> 00:18:29,810
データソースプロバイダは

259
00:18:29,910 --> 00:18:34,882
Just-In-Timeロードと
パージを行います

260
00:18:35,582 --> 00:18:39,953
そのため １つのカーネルに
重みをロードし

261
00:18:40,053 --> 00:18:43,690
次の畳み込みカーネルに
移る前にパージできます

262
00:18:46,193 --> 00:18:48,729
これがMyWeightsの実装です

263
00:18:49,363 --> 00:18:52,466
初期化メソッドを使い

264
00:18:52,566 --> 00:18:56,003
メモリに取り込み 準備します

265
00:18:56,103 --> 00:18:58,939
グラフがロード機能を
呼び出した後は

266
00:18:59,039 --> 00:19:03,043
パージメソッドが呼び出され
重みを解放できます

267
00:18:59,039 --> 00:19:03,043
パージメソッドが呼び出され
重みを解放できます

268
00:19:03,577 --> 00:19:06,447
訓練に必須の
データソースプロバイダは

269
00:19:06,547 --> 00:19:08,782
後ほど詳細に扱います

270
00:19:11,852 --> 00:19:16,290
訓練グラフを作り
入力と重みが準備できると

271
00:19:16,390 --> 00:19:18,892
GPUでグラフを実行できます

272
00:19:20,360 --> 00:19:25,065
GPU上でのグラフ変更は
Metal Setupで行います

273
00:19:25,299 --> 00:19:29,570
訓練グラフを初期化し
入力の用意ができました

274
00:19:29,670 --> 00:19:32,306
訓練を始めましょう

275
00:19:35,042 --> 00:19:39,980
訓練は反復プロセスのため
訓練ループを設定します

276
00:19:40,514 --> 00:19:44,484
設定したエポック数分
実行されます

277
00:19:44,751 --> 00:19:46,286
エポック数とは

278
00:19:46,386 --> 00:19:51,258
データセット全体で
反復したい数のことです

279
00:19:51,692 --> 00:19:54,728
各エポックで
複数の反復とします

280
00:19:54,862 --> 00:19:58,499
反復回数はデータセットの
画像総数を

281
00:19:58,599 --> 00:20:01,502
32か64のバッチで
割ったものです

282
00:19:58,599 --> 00:20:01,502
32か64のバッチで
割ったものです

283
00:20:02,135 --> 00:20:05,038
では 訓練反復を見ましょう

284
00:20:07,040 --> 00:20:12,146
各訓練反復では画像バッチを
エンコードします

285
00:20:13,046 --> 00:20:18,752
しかし GPUが画像バッチの
処理を終わるのをCPUが待ち

286
00:20:18,852 --> 00:20:21,622
エンコードコマンドを

287
00:20:21,722 --> 00:20:26,960
コマンドバッファに送るのは
望ましくありません

288
00:20:27,461 --> 00:20:31,198
CPUとGPUを
同時に動かしたいのです

289
00:20:31,298 --> 00:20:33,734
そこで
ダブルバッファです

290
00:20:34,401 --> 00:20:40,340
今回の設定では初期値２の
計数セマフォを作ります

291
00:20:40,440 --> 00:20:44,411
２つのエンコードだけ
同時進行させたいからです

292
00:20:45,579 --> 00:20:52,085
訓練反復関数を入力し
セマフォに重みを呼び出します

293
00:20:52,786 --> 00:20:58,392
カウント値が０であれば待ち
それ以外は継続します

294
00:20:59,426 --> 00:21:03,831
すぐにエンコードコールが
返ってきます

295
00:20:59,426 --> 00:21:03,831
すぐにエンコードコールが
返ってきます

296
00:21:04,097 --> 00:21:08,836
GPUのグラフ実行が終わると
ユーザ指定コールバックです

297
00:21:09,303 --> 00:21:11,905
GPUのグラフ処理が終了し

298
00:21:12,005 --> 00:21:16,810
CPUはGPUに処理の
エンコードを継続させます

299
00:21:17,578 --> 00:21:20,280
セマファで
待っていた処理です

300
00:21:21,281 --> 00:21:22,683
なぜダブルバッファで

301
00:21:22,783 --> 00:21:27,821
GPUのグラフ実行と
同時ではないのでしょうか？

302
00:21:28,689 --> 00:21:33,527
コマンドバッファの方が
時間がかからないからです

303
00:21:33,627 --> 00:21:38,565
メモリの使用を減らすため
同時処理を避けています

304
00:21:41,235 --> 00:21:43,670
グラフを実行すると

305
00:21:43,771 --> 00:21:49,142
フォワードパス 損失計算
勾配のパスを行い

306
00:21:49,243 --> 00:21:51,345
グラフは重みを更新します

307
00:21:51,478 --> 00:21:53,914
では 重みの更新を見ましょう

308
00:21:55,782 --> 00:22:00,888
データソースプロバイダは
訓練に必須であり

309
00:21:55,782 --> 00:22:00,888
データソースプロバイダは
訓練に必須であり

310
00:22:01,455 --> 00:22:06,627
任意の更新メソッドで
重みの更新が必要です

311
00:22:07,661 --> 00:22:10,998
更新メソッドは自動ですが

312
00:22:11,098 --> 00:22:14,635
具体的なステップを
見てみましょう

313
00:22:16,870 --> 00:22:19,773
勾配のパス中に勾配を計算し

314
00:22:19,873 --> 00:22:24,244
各訓練で重みに
小さいデルタを適用します

315
00:22:25,379 --> 00:22:30,284
どうやるかはオプティマイザで
記述されています

316
00:22:30,484 --> 00:22:35,689
この関数は古い重みと
計算済みの勾配を入力として

317
00:22:35,789 --> 00:22:39,560
更新した重みを出力として
生成します

318
00:22:41,094 --> 00:22:45,232
更新にはオプティマイザを
使用するでしょう

319
00:22:45,899 --> 00:22:50,304
様々な重み更新の
バリアントをサポートしています

320
00:22:50,404 --> 00:22:54,107
Adamや確率的勾配降下法
RMSPropなどです

321
00:22:54,708 --> 00:22:59,580
重み更新は自分で
定義することもできます

322
00:22:59,913 --> 00:23:03,951
では MPSでの
オプティマイザの使い方を見ます

323
00:22:59,913 --> 00:23:03,951
では MPSでの
オプティマイザの使い方を見ます

324
00:23:06,153 --> 00:23:09,423
データソースプロバイダは
initメソッドです

325
00:23:09,523 --> 00:23:14,061
オプティマイザを作るのは
１回だけです

326
00:23:15,229 --> 00:23:18,766
更新メソッドの実行を
見ましょう

327
00:23:19,433 --> 00:23:24,371
入力はソースステートと
勾配ステートです

328
00:23:26,039 --> 00:23:28,375
ソースステートは古い重みを

329
00:23:28,475 --> 00:23:31,478
勾配ステートは
計算済み勾配を含みます

330
00:23:31,578 --> 00:23:37,351
オプティマイザをエンコードし
最後にソースステートを返します

331
00:23:37,451 --> 00:23:40,721
重みが更新されました
簡単ですね

332
00:23:43,590 --> 00:23:46,093
もう１ステップあります

333
00:23:46,226 --> 00:23:51,465
繰り返しますが
ネットワーク訓練は反復です

334
00:23:52,699 --> 00:23:54,968
いつ訓練をやめるか

335
00:23:55,135 --> 00:24:00,407
訓練ループの観点から
どう決定するかお話しします

336
00:23:55,135 --> 00:24:00,407
訓練ループの観点から
どう決定するかお話しします

337
00:24:03,243 --> 00:24:08,048
訓練をエポックの回数分行う
訓練ループです

338
00:24:09,116 --> 00:24:13,153
まずは画像の
テストセットが必要です

339
00:24:13,253 --> 00:24:17,858
これには訓練に使用しなかった
画像も含まれています

340
00:24:17,958 --> 00:24:21,828
これらは精度の評価のみに
使われます

341
00:24:22,262 --> 00:24:25,299
各エポックごとに任意で

342
00:24:25,399 --> 00:24:29,503
GPUがグラフ実行を
やめるのを待ちます

343
00:24:29,636 --> 00:24:35,943
現在の訓練済みパラメータを使い
推論ネットワークを初期化します

344
00:24:36,743 --> 00:24:40,180
テストセットでこれを実行し

345
00:24:40,280 --> 00:24:44,952
ネットワークの精度が
あるレベルに達したら

346
00:24:45,052 --> 00:24:46,687
訓練をやめます

347
00:24:49,857 --> 00:24:52,493
MPSでの
ネットワーク訓練に

348
00:24:52,593 --> 00:24:55,863
必要なステップを
お話ししました

349
00:24:55,963 --> 00:24:57,364
次はデモです

350
00:24:58,599 --> 00:25:02,102
他のセッションで
お話ししたように

351
00:24:58,599 --> 00:25:02,102
他のセッションで
お話ししたように

352
00:25:02,603 --> 00:25:05,505
MPSフレームワークは

353
00:25:06,340 --> 00:25:09,543
Core MLやCreate ML
Turi Createを動かします

354
00:25:10,144 --> 00:25:14,715
Turi Createは簡単かつ
フレキシブルで高性能な

355
00:25:14,815 --> 00:25:18,051
Core MLを
作るツールセットです

356
00:25:18,352 --> 00:25:25,058
画像分類 オブジェクト検出
推薦など 様々なタスクが可能です

357
00:25:25,159 --> 00:25:30,964
Turi Createの詳細は
セッションビデオをご覧ください

358
00:25:32,166 --> 00:25:36,270
このデモで
Turi Createによる

359
00:25:36,370 --> 00:25:42,142
オブジェクト検出ネットワークの
訓練をします

360
00:25:42,943 --> 00:25:46,647
Platforms State of the Unionで
言ったように

361
00:25:46,747 --> 00:25:49,483
MPSを使うと
９倍速くなります

362
00:25:50,050 --> 00:25:55,455
認識したオブジェクトに
境界ボックスが描かれます

363
00:26:01,195 --> 00:26:02,463
デモで使うのは

364
00:26:04,765 --> 00:26:08,569
MacBook Proと外付けGPUです

365
00:26:09,770 --> 00:26:12,906
Turi CreateをMacBook Proで

366
00:26:13,307 --> 00:26:18,245
外付けGPUを使い
MPSで訓練を行います

367
00:26:18,812 --> 00:26:24,852
MacBook Proの計算能力を
外付けGPUで高める絶好の例です

368
00:26:25,152 --> 00:26:28,489
外付けGPUは
AMD Vega GPUです

369
00:26:29,289 --> 00:26:32,693
Turi Createは
インポート済みで

370
00:26:32,793 --> 00:26:37,765
オブジェクト検出ネットワークと
訓練データセットも既にあります

371
00:26:37,865 --> 00:26:43,003
まず10回の反復で
ネットワークの訓練を行い―

372
00:26:44,671 --> 00:26:46,840
次にネットワーク全体に
適用します

373
00:26:46,940 --> 00:26:50,611
全てのプリミティブと
オプティマイザ 重み更新は―

374
00:26:52,279 --> 00:26:55,015
外付けGPUで動いています

375
00:26:58,085 --> 00:27:00,754
10回の訓練が終わりました

376
00:26:58,085 --> 00:27:00,754
10回の訓練が終わりました

377
00:27:01,221 --> 00:27:05,826
実際は 回数がもっと多いですが
デモでは省略します

378
00:27:05,959 --> 00:27:11,198
では 前もって訓練した
ネットワークをロードし

379
00:27:11,298 --> 00:27:15,903
実行した結果を
映像でお見せしましょう

380
00:27:18,238 --> 00:27:20,107
これはバナナです

381
00:27:20,207 --> 00:27:24,278
境界ボックスで囲まれ
正しく分類されています

382
00:27:24,878 --> 00:27:28,782
朝食の
コーヒーとクロワッサン

383
00:27:29,116 --> 00:27:31,818
それに怖い顔の卵です

384
00:27:34,254 --> 00:27:36,690
以上 Turi Createのデモでした

385
00:27:37,324 --> 00:27:43,297
(拍手)

386
00:27:43,397 --> 00:27:44,565
ありがとうございます

387
00:27:47,468 --> 00:27:51,538
次は リカレントニューラル
ネットワークの訓練です

388
00:27:52,306 --> 00:27:55,809
まずは
おさらいから始めます

389
00:27:57,244 --> 00:28:00,147
CNNの欠点の１つは

390
00:27:57,244 --> 00:28:00,147
CNNの欠点の１つは

391
00:28:00,247 --> 00:28:04,685
以前起こったことを
記憶できない点です

392
00:28:05,219 --> 00:28:07,755
１つの入力を取り込み

393
00:28:07,855 --> 00:28:13,827
画像の可能性のあるものを
単一出力として生成します

394
00:28:16,530 --> 00:28:19,700
一方 RNNは
記憶することができ

395
00:28:19,800 --> 00:28:24,037
入力と出力の
シーケンスが得意です

396
00:28:24,538 --> 00:28:28,976
例えば 画像の中の１つの
確率のセットを取り込みます

397
00:28:29,109 --> 00:28:31,111
それがCNNの出力です

398
00:28:31,211 --> 00:28:33,380
CNNが生成するものが

399
00:28:33,480 --> 00:28:37,084
画像のキャプションとなる
単語のシーケンスです

400
00:28:38,252 --> 00:28:44,224
文を構成する単語のシーケンスを
入力として取り込み

401
00:28:44,324 --> 00:28:49,029
例えばロシア語と
フィンランド語など

402
00:28:49,129 --> 00:28:52,933
異なる言語に翻訳された文を
出力できます

403
00:28:54,735 --> 00:28:59,807
多くのRNNのモデルの中でも
最も一般的なのが

404
00:28:59,907 --> 00:29:03,877
Long Short-Term Memory
略してLSTMでしょう

405
00:28:59,907 --> 00:29:03,877
Long Short-Term Memory
略してLSTMでしょう

406
00:29:04,545 --> 00:29:10,050
既に昨年のWWDCで
LSTMのゲートを詳しく扱い

407
00:29:10,150 --> 00:29:13,420
LSTM推論の例も
お見せしました

408
00:29:13,620 --> 00:29:18,325
LSTMの詳細は
当該セッションをご覧ください

409
00:29:19,459 --> 00:29:24,598
今年はRNNの全部の
モデルをサポートします

410
00:29:25,099 --> 00:29:29,603
このセッションでは
LSTMの訓練について話します

411
00:29:32,439 --> 00:29:34,374
具体例を見ましょう

412
00:29:34,608 --> 00:29:40,414
行動の分類ネットワークは
動作感覚データを入力とします

413
00:29:40,514 --> 00:29:45,119
例えば 加速度計などの
センサの読み取り値です

414
00:29:45,485 --> 00:29:50,924
そのデータを元に
ユーザの身体行動を識別します

415
00:29:51,024 --> 00:29:56,163
例えば サイクリング中か
ウォーキング中かなどです

416
00:29:58,999 --> 00:30:03,370
興味深い
ネットワーク設定でしょう

417
00:29:58,999 --> 00:30:03,370
興味深い
ネットワーク設定でしょう

418
00:30:03,470 --> 00:30:08,008
含まれるプリミティブは
CNNに続いて

419
00:30:08,108 --> 00:30:12,412
LSTM またCNNと
なっています

420
00:30:12,513 --> 00:30:14,948
なぜこんな設定に？

421
00:30:16,817 --> 00:30:19,820
入力されたセンサデータは

422
00:30:20,420 --> 00:30:24,124
６つのチャネルによる
1D画像で表されます

423
00:30:24,224 --> 00:30:29,763
チャネルの１つが加速度計などの
数字を読み取ります

424
00:30:30,564 --> 00:30:33,867
各1D画像は
2000ピクセルです

425
00:30:33,967 --> 00:30:37,438
これを時間サンプルと
考えます

426
00:30:37,638 --> 00:30:41,808
識別したい行動は
経時的に起こるからです

427
00:30:44,545 --> 00:30:48,582
1D畳み込みプリミティブを
通じて

428
00:30:49,116 --> 00:30:54,054
画像は2000から
20サンプルに絞られます

429
00:30:56,023 --> 00:30:58,158
多数の特徴チャネルを
使うので

430
00:30:58,258 --> 00:31:01,628
データの特徴は
失われていません

431
00:30:58,258 --> 00:31:01,628
データの特徴は
失われていません

432
00:31:03,096 --> 00:31:09,603
これが長さが20のシーケンスとして
LSTMのプリミティブに渡されます

433
00:31:10,304 --> 00:31:12,606
LSTMを20反復 実行します

434
00:31:12,740 --> 00:31:16,910
LSTMは2000ではなく
20の長さで動作するので

435
00:31:17,010 --> 00:31:20,781
より高度な特徴のデータと
なっています

436
00:31:22,416 --> 00:31:25,018
追加のCNNの
プリミティブも

437
00:31:25,352 --> 00:31:28,589
データに高度な特徴を
持っています

438
00:31:29,289 --> 00:31:32,960
最後は
SoftMaxプリミティブです

439
00:31:33,060 --> 00:31:36,296
異なるアクティビティクラスの
確率を生成

440
00:31:36,396 --> 00:31:38,098
これが出力になります

441
00:31:38,565 --> 00:31:41,135
では 訓練について話します

442
00:31:42,169 --> 00:31:44,771
必要なのは
損失のプリミティブで

443
00:31:44,872 --> 00:31:48,308
ネットワークの出力と
ラベルを入力とします

444
00:31:48,475 --> 00:31:52,279
そして 後半のグラフが
必要となります

445
00:31:52,379 --> 00:31:56,216
対応するフォワードプリミティブの
勾配プリミティブは

446
00:31:56,316 --> 00:31:58,418
LSTMのプリミティブなどです

447
00:31:58,986 --> 00:32:00,621
訓練するために

448
00:31:58,986 --> 00:32:00,621
訓練するために

449
00:32:01,655 --> 00:32:06,760
ネットワークで フォワードパスと
損失計算を行います

450
00:32:07,494 --> 00:32:12,399
そして勾配のパスで 勾配を計算し
重みを更新します

451
00:32:12,499 --> 00:32:16,904
これはCNN訓練の
設定に似ています

452
00:32:17,004 --> 00:32:19,706
最後はもちろん重み更新です

453
00:32:19,807 --> 00:32:23,977
LSTMも重みがあり
更新が必要です

454
00:32:25,979 --> 00:32:30,484
このネットワークを
MPSで訓練します

455
00:32:30,584 --> 00:32:35,823
フレームワークを使った
LSTM層の作り方を見ましょう

456
00:32:36,490 --> 00:32:39,593
まず LSTM層の記述子を
作ります

457
00:32:40,494 --> 00:32:46,200
データソースプロバイダを使い
記述子を初期化します

458
00:32:46,300 --> 00:32:48,402
初期化訓練パラメータは

459
00:32:48,502 --> 00:32:51,672
小さなランダム数字か
チェックポイント値です

460
00:32:52,306 --> 00:32:57,077
訓練の記述子の設定は
推論と全く同じです

461
00:32:58,479 --> 00:33:04,952
Layer Descriptor Setupの詳細は
昨年のWWDCで説明されました

462
00:32:58,479 --> 00:33:04,952
Layer Descriptor Setupの詳細は
昨年のWWDCで説明されました

463
00:33:05,052 --> 00:33:10,657
詳しい情報は当該セッションを
ご参照ください

464
00:33:11,091 --> 00:33:12,893
記述子ができたら

465
00:33:13,794 --> 00:33:17,931
次に これで
LSTMの訓練層を作ります

466
00:33:19,666 --> 00:33:25,873
MPSは訓練の重みを埋め込むのに
指定したデータソースを使います

467
00:33:26,039 --> 00:33:29,943
計算済み勾配を保つ
マトリクスも必要です

468
00:33:30,677 --> 00:33:33,914
マトリクスを作るのに―

469
00:33:34,014 --> 00:33:37,417
WeightGradientMatrices APIが
使えます

470
00:33:37,651 --> 00:33:42,689
訓練の重みはフォワードと
勾配のパスで使われ

471
00:33:42,790 --> 00:33:47,427
計算済み勾配と共に
オプティマイザに渡されます

472
00:33:49,263 --> 00:33:53,767
LSTMの訓練用の
入力と出力を準備します

473
00:33:54,401 --> 00:33:59,673
これは 入力と出力シーケンスを
保つマトリクスを作る例です

474
00:33:59,773 --> 00:34:04,978
フォワードと勾配のパスに
各20のマトリクスが必要です

475
00:33:59,773 --> 00:34:04,978
フォワードと勾配のパスに
各20のマトリクスが必要です

476
00:34:05,612 --> 00:34:09,049
こうしてマトリクスを
初期化します

477
00:34:11,685 --> 00:34:15,922
これでMPSによる
訓練を始められます

478
00:34:16,023 --> 00:34:21,728
ここでハイライトするのは
時間に関するLSTMフィルタのみです

479
00:34:23,429 --> 00:34:29,136
フォワードパスで
20のマトリクスを実行します

480
00:34:29,703 --> 00:34:31,038
バックワードパスでは

481
00:34:31,138 --> 00:34:35,809
20のマトリクスを実行し
勾配を計算します

482
00:34:36,543 --> 00:34:40,681
これで訓練の重みと
計算済み勾配ができ

483
00:34:40,781 --> 00:34:44,251
オプティマイザに渡し
重みを更新します

484
00:34:45,619 --> 00:34:48,054
１つ言いたいことは

485
00:34:49,289 --> 00:34:55,362
CNNは画像で LSTMは
マトリクスで動きます

486
00:34:55,896 --> 00:34:59,032
カーネルに利便性を与えると

487
00:34:59,133 --> 00:35:02,502
画像とマトリクスの変換が
容易になるのです

488
00:34:59,133 --> 00:35:02,502
画像とマトリクスの変換が
容易になるのです

489
00:35:03,003 --> 00:35:06,507
画像をマトリクスに
コピーするため

490
00:35:06,607 --> 00:35:10,010
MPSImageCopyToMatrixを
使います

491
00:35:10,110 --> 00:35:12,012
これでできました

492
00:35:12,112 --> 00:35:16,149
画像のバッチで
エンコードできます

493
00:35:17,017 --> 00:35:19,920
各デスティネーション
マトリクスは

494
00:35:20,020 --> 00:35:22,189
１つのソース画像を
含んでいます

495
00:35:22,923 --> 00:35:25,392
マトリクスからのコピーは

496
00:35:25,792 --> 00:35:29,062
MPS Matrix Copy to
Image Kernelを使います

497
00:35:29,163 --> 00:35:33,467
こうしてGPUに
エンコードします

498
00:35:35,235 --> 00:35:41,041
MPSを使ったCNNとRNNの
訓練をお見せして―

499
00:35:41,708 --> 00:35:46,013
MPSによるTuri Createの
デモもお見せしました

500
00:35:46,113 --> 00:35:48,148
デモはもう１つあります

501
00:35:49,416 --> 00:35:55,222
GoogleとTensorFlowへの
サポートを行ってきたのは

502
00:35:55,656 --> 00:35:59,059
macOSの機械学習を
加速するためです

503
00:35:59,159 --> 00:36:01,361
そのデモをご覧ください

504
00:35:59,159 --> 00:36:01,361
そのデモをご覧ください

505
00:36:01,461 --> 00:36:03,897
特に注目してほしいのは

506
00:36:03,997 --> 00:36:07,668
MPSによる
TensorFlowを使った

507
00:36:08,001 --> 00:36:11,004
InceptionV3の
オブジェクト分類の訓練です

508
00:36:11,638 --> 00:36:12,706
このデモでも

509
00:36:14,475 --> 00:36:18,745
MacBook Proに
外付けGPUを接続します

510
00:36:19,179 --> 00:36:23,116
MacBook Proで
TensorFlowを実行し

511
00:36:23,217 --> 00:36:27,721
外付けGPUで
MPSによる訓練を行います

512
00:36:27,821 --> 00:36:32,226
このデモ用に
TensorFlowはインポート済み

513
00:36:32,326 --> 00:36:35,963
InceptionV3とデータセットも
ロード済みです

514
00:36:36,063 --> 00:36:39,767
30反復で
ネットワークを訓練します

515
00:36:40,834 --> 00:36:42,936
速いでしょう

516
00:36:43,303 --> 00:36:47,875
全てのプリミティブ
オプティマイザ 重み更新は

517
00:36:47,975 --> 00:36:50,510
外付けGPUで
実行されています

518
00:36:50,611 --> 00:36:52,112
もう終わりました

519
00:36:52,379 --> 00:36:57,351
訓練速度はおよそ
毎秒100画像です

520
00:36:57,684 --> 00:37:00,954
既に言われているように

521
00:36:57,684 --> 00:37:00,954
既に言われているように

522
00:37:01,155 --> 00:37:06,427
MPSによるTensorFlowの
InceptionV3ネットワーク訓練は

523
00:37:06,660 --> 00:37:10,664
MPS無しに比べ
20倍の速さです

524
00:37:11,165 --> 00:37:13,267
TensorFlowのデモでした

525
00:37:14,368 --> 00:37:16,003
(拍手)

526
00:37:16,103 --> 00:37:16,904
ありがとう

527
00:37:22,009 --> 00:37:23,977
セッションのまとめです

528
00:37:24,745 --> 00:37:31,318
今年 畳み込みと転置畳み込み用に
FP16の蓄積を追加しました

529
00:37:31,485 --> 00:37:34,955
CNNの推論を
向上させるためです

530
00:37:35,122 --> 00:37:39,259
訓練用に追加された
GPUで加速化したプリミティブは

531
00:37:39,359 --> 00:37:43,497
iOSとmacOSに
最適化されています

532
00:37:44,631 --> 00:37:47,801
ニューラルネットワーク
グラフAPIも追加され

533
00:37:48,335 --> 00:37:51,572
GPUでの訓練を
容易にしました

534
00:37:51,672 --> 00:37:56,510
異なるGPUで最高の
パフォーマンスを引き出しています

535
00:37:58,612 --> 00:38:04,184
さらに詳しい情報は
デベロッパWebサイトへ

536
00:37:58,612 --> 00:38:04,184
さらに詳しい情報は
デベロッパWebサイトへ

537
00:38:05,452 --> 00:38:10,657
Metal for Machine
Learningラボは明日９時からです

538
00:38:10,758 --> 00:38:12,326
ご参加ください

539
00:38:13,794 --> 00:38:17,931
ありがとうございました
WWDCをお楽しみください

540
00:38:18,031 --> 00:38:19,333
(拍手)