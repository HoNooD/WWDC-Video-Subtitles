1
00:00:01,516 --> 00:00:04,500
[ Music ]


2
00:00:08,045 --> 00:00:09,296
>> Hello and welcome to our


3
00:00:09,296 --> 00:00:11,656
session about audio API updates.


4
00:00:12,116 --> 00:00:14,116
My name is Peter Vasil and I am


5
00:00:14,116 --> 00:00:15,656
a software engineer in the Core


6
00:00:15,656 --> 00:00:16,276
Audio team.


7
00:00:18,426 --> 00:00:20,066
Let's start with what's new in


8
00:00:20,066 --> 00:00:21,186
AVAudioEngine.


9
00:00:24,206 --> 00:00:25,226
We have added a couple of


10
00:00:25,226 --> 00:00:26,976
enhancements and new API's to


11
00:00:26,976 --> 00:00:27,996
AVAudioEngine.


12
00:00:28,946 --> 00:00:30,446
We now have a voice processing


13
00:00:30,446 --> 00:00:30,946
support.


14
00:00:31,946 --> 00:00:33,486
We have added two new nodes,


15
00:00:33,736 --> 00:00:35,346
AVAudioSourceNode and


16
00:00:35,346 --> 00:00:36,506
AVAudiSinkNode.


17
00:00:37,266 --> 00:00:38,086
And we have made some


18
00:00:38,086 --> 00:00:39,576
improvements to special audio


19
00:00:39,576 --> 00:00:40,256
rendering.


20
00:00:41,616 --> 00:00:42,946
Now let's dive into the details.


21
00:00:46,286 --> 00:00:48,236
AVAudioEngine now has a voice


22
00:00:48,236 --> 00:00:49,156
processing mode.


23
00:00:49,726 --> 00:00:51,916
The main use case for the mode


24
00:00:51,916 --> 00:00:53,256
is echo cancellation in


25
00:00:53,256 --> 00:00:54,926
voiceover IP applications.


26
00:00:55,966 --> 00:00:56,836
What does this mean?


27
00:00:57,836 --> 00:00:59,346
When enabled, extra signal


28
00:00:59,346 --> 00:01:00,826
processing is applied on the


29
00:01:00,826 --> 00:01:03,286
incoming audio and any audio


30
00:01:03,286 --> 00:01:04,676
that is coming from the device


31
00:01:04,676 --> 00:01:06,046
is taken out.


32
00:01:06,816 --> 00:01:09,136
This requires that both input


33
00:01:09,136 --> 00:01:10,506
and output nodes are in the


34
00:01:10,506 --> 00:01:11,686
voice processing mode.


35
00:01:13,126 --> 00:01:15,236
Therefore, when enabling the


36
00:01:15,236 --> 00:01:16,966
mode on either of the I/O nodes,


37
00:01:17,536 --> 00:01:19,556
the engine takes care that both


38
00:01:19,556 --> 00:01:21,406
I/O nodes exist and that they


39
00:01:21,406 --> 00:01:22,506
are switched to the voice


40
00:01:22,506 --> 00:01:23,336
processing mode.


41
00:01:24,966 --> 00:01:26,296
Voice processing is only


42
00:01:26,296 --> 00:01:27,886
available when rendering to an


43
00:01:27,886 --> 00:01:29,906
audio device, not a manual


44
00:01:29,906 --> 00:01:30,746
rendering mode.


45
00:01:34,326 --> 00:01:35,966
To enable or disable voice


46
00:01:35,966 --> 00:01:38,456
processing, we can use set voice


47
00:01:38,496 --> 00:01:40,616
processing enabled on either the


48
00:01:40,616 --> 00:01:42,066
input or output node.


49
00:01:43,406 --> 00:01:44,826
Voice processing cannot be


50
00:01:44,826 --> 00:01:47,046
enabled dynamically, which means


51
00:01:47,106 --> 00:01:48,586
the engine needs to be in a stop


52
00:01:48,586 --> 00:01:50,506
state when enabling the mode.


53
00:01:50,996 --> 00:01:54,296
The AVEchoTouch sample code


54
00:01:54,296 --> 00:01:56,726
project demonstrates how to use


55
00:01:56,726 --> 00:01:57,826
voice processing with


56
00:01:57,826 --> 00:01:58,976
AVAudioEngine in detail.


57
00:02:01,516 --> 00:02:03,616
Let's look at the new nodes in


58
00:02:03,616 --> 00:02:06,376
AVAudioEngine: AVAudioSourceNode


59
00:02:06,376 --> 00:02:07,766
and AVAudioSinkNode.


60
00:02:08,966 --> 00:02:10,826
Both nodes wrap a user-defined


61
00:02:10,826 --> 00:02:12,836
block that allows users to send


62
00:02:12,836 --> 00:02:14,006
or receive audio from


63
00:02:14,006 --> 00:02:15,006
AVAudioEngine.


64
00:02:16,176 --> 00:02:17,646
When rendering to an audio


65
00:02:17,646 --> 00:02:20,056
device, the block operates under


66
00:02:20,056 --> 00:02:21,476
real-time constraints which


67
00:02:21,476 --> 00:02:22,796
means that within the block


68
00:02:22,796 --> 00:02:24,156
there shouldn't be any blocking


69
00:02:24,156 --> 00:02:26,106
cause like memory allocations,


70
00:02:26,566 --> 00:02:28,586
call to dispatch or blocking on


71
00:02:28,586 --> 00:02:28,976
a mutex.


72
00:02:33,046 --> 00:02:35,166
With AVAudioSourceNode, we pass


73
00:02:35,166 --> 00:02:36,796
a render block to the node which


74
00:02:36,796 --> 00:02:38,736
sends audio data to its output.


75
00:02:40,066 --> 00:02:41,626
This makes it very easy to


76
00:02:41,626 --> 00:02:43,446
create generator nodes without


77
00:02:43,446 --> 00:02:45,406
having to implement a full audio


78
00:02:45,406 --> 00:02:46,706
unit and wrap it with


79
00:02:46,706 --> 00:02:47,486
AVAudioUnit.


80
00:02:49,046 --> 00:02:51,306
The node can be used in both


81
00:02:51,306 --> 00:02:52,936
real-time and manual rendering


82
00:02:52,936 --> 00:02:53,246
mode.


83
00:02:54,476 --> 00:02:56,406
AVAudioSourceNode supports


84
00:02:56,406 --> 00:02:58,936
linear PCM conversions such as


85
00:02:58,936 --> 00:03:00,246
sample rate or bit depth


86
00:03:00,246 --> 00:03:01,056
conversions.


87
00:03:01,616 --> 00:03:04,536
And has one output but no


88
00:03:04,536 --> 00:03:04,976
inputs.


89
00:03:09,436 --> 00:03:11,476
This short code snippet shows


90
00:03:11,476 --> 00:03:13,366
how to use AVAudioSourceNode.


91
00:03:14,056 --> 00:03:16,096
As we can see, the block is


92
00:03:16,096 --> 00:03:18,126
passed as an initializer


93
00:03:18,126 --> 00:03:19,986
argument and after creating the


94
00:03:19,986 --> 00:03:21,896
node it can be connected just


95
00:03:21,896 --> 00:03:22,906
like any other node.


96
00:03:23,936 --> 00:03:25,676
A more detailed example can be


97
00:03:25,676 --> 00:03:27,306
found in our signal generator


98
00:03:27,306 --> 00:03:27,976
sample code project.


99
00:03:32,356 --> 00:03:34,166
Let's look at AVAudioSinkNode.


100
00:03:34,866 --> 00:03:37,156
AVAudioSinkNode is a symmetrical


101
00:03:37,156 --> 00:03:37,876
counterpart of


102
00:03:37,876 --> 00:03:39,256
AVAudioSourceNode.


103
00:03:40,086 --> 00:03:41,916
It wraps a user-defined block


104
00:03:41,966 --> 00:03:43,636
that receives the input audio


105
00:03:43,636 --> 00:03:45,086
from the node chain that is


106
00:03:45,086 --> 00:03:46,446
connected to its input.


107
00:03:47,516 --> 00:03:49,796
AVAudioSinkNode is restricted to


108
00:03:49,796 --> 00:03:52,036
the input chain, in other words


109
00:03:52,276 --> 00:03:53,866
it must be connected downstream


110
00:03:53,866 --> 00:03:54,796
of the input node.


111
00:03:56,076 --> 00:03:57,496
It does not support format


112
00:03:57,496 --> 00:03:58,186
conversions.


113
00:03:58,626 --> 00:04:00,096
And the format within the block


114
00:04:00,356 --> 00:04:01,606
has to be the same as the


115
00:04:01,606 --> 00:04:02,836
hardware input format.


116
00:04:04,236 --> 00:04:06,436
The node can be useful for


117
00:04:06,436 --> 00:04:09,086
voiceover IP application when


118
00:04:09,086 --> 00:04:10,756
the input needs to be processed


119
00:04:10,756 --> 00:04:12,596
in real time, in which case


120
00:04:12,596 --> 00:04:14,256
installing a regular tap would


121
00:04:14,256 --> 00:04:16,386
not be sufficient because a tap


122
00:04:16,726 --> 00:04:18,216
doesn't operate in a real-time


123
00:04:18,216 --> 00:04:18,815
context.


124
00:04:21,076 --> 00:04:22,746
Here is a code snippet


125
00:04:22,746 --> 00:04:24,636
demonstrating how to create an


126
00:04:24,636 --> 00:04:25,826
AVAudioSinkNode.


127
00:04:26,466 --> 00:04:28,086
It is quite similar to


128
00:04:28,086 --> 00:04:29,206
AVAudioSourceNode.


129
00:04:29,976 --> 00:04:32,096
The main steps to note here are


130
00:04:32,096 --> 00:04:33,606
to initialize the node with a


131
00:04:33,606 --> 00:04:35,836
block, attach it to the engine


132
00:04:36,146 --> 00:04:37,676
and connect it to a node


133
00:04:37,676 --> 00:04:38,976
downstream of the input node.


134
00:04:43,046 --> 00:04:44,266
Now let's see the spatial


135
00:04:44,266 --> 00:04:45,576
rendering improvements.


136
00:04:46,666 --> 00:04:48,426
We have introduced an automatic


137
00:04:48,426 --> 00:04:51,256
spatial rendering algorithm, and


138
00:04:51,256 --> 00:04:53,486
AVAudioPlayer node now supports


139
00:04:53,486 --> 00:04:55,636
specialization of multichannel


140
00:04:55,636 --> 00:04:55,976
audio content.


141
00:05:01,076 --> 00:05:02,076
With the automatic spatial


142
00:05:02,076 --> 00:05:03,806
rendering algorithm, the most


143
00:05:03,806 --> 00:05:05,446
appropriate specialization


144
00:05:05,446 --> 00:05:06,936
algorithm is selected for the


145
00:05:06,936 --> 00:05:07,786
current route.


146
00:05:08,626 --> 00:05:10,576
This means developers don't need


147
00:05:10,576 --> 00:05:12,436
to figure out what algorithms


148
00:05:12,436 --> 00:05:14,066
are suitable for headphones or


149
00:05:14,066 --> 00:05:14,786
different speaker


150
00:05:14,786 --> 00:05:15,816
configurations.


151
00:05:16,896 --> 00:05:18,386
This adds near field and


152
00:05:18,386 --> 00:05:19,566
inherent rendering for


153
00:05:19,566 --> 00:05:21,886
headphones and virtual surround


154
00:05:21,886 --> 00:05:23,566
for built-in speakers is


155
00:05:23,566 --> 00:05:25,226
available starting with iOS


156
00:05:25,226 --> 00:05:27,926
devices and laptops from 2018


157
00:05:28,076 --> 00:05:28,646
and newer.


158
00:05:32,096 --> 00:05:34,026
Here we see the new API and the


159
00:05:34,026 --> 00:05:36,126
AVAudio3DMixing protocol.


160
00:05:36,746 --> 00:05:39,656
The AVAudio3DMixing rendering


161
00:05:39,656 --> 00:05:42,076
algorithm ENUM has a new entry:


162
00:05:42,476 --> 00:05:43,006
auto.


163
00:05:44,056 --> 00:05:45,926
Additionally, we can specify the


164
00:05:45,926 --> 00:05:47,606
output type with the output type


165
00:05:47,606 --> 00:05:47,976
property.


166
00:05:50,666 --> 00:05:52,346
With the property set to auto,


167
00:05:52,636 --> 00:05:54,146
the output type can be


168
00:05:54,146 --> 00:05:56,346
automatically detected in


169
00:05:56,346 --> 00:05:58,266
real-time mode but not in manual


170
00:05:58,266 --> 00:05:58,976
rendering mode.


171
00:06:03,396 --> 00:06:05,116
With the ability to specialize


172
00:06:05,116 --> 00:06:07,546
multichannel streams, we support


173
00:06:07,546 --> 00:06:09,316
point source and ambience bed


174
00:06:09,316 --> 00:06:09,916
rendering.


175
00:06:10,816 --> 00:06:12,476
We also support channel-based


176
00:06:12,476 --> 00:06:14,066
formats and high-order


177
00:06:14,066 --> 00:06:15,576
Ambisonics up to the third


178
00:06:15,576 --> 00:06:15,926
order.


179
00:06:20,046 --> 00:06:20,786
We have added two new


180
00:06:20,786 --> 00:06:22,706
specialization properties to the


181
00:06:22,706 --> 00:06:25,946
AVAudio3DMixing protocol: source


182
00:06:25,946 --> 00:06:27,606
mode and point source and head


183
00:06:27,606 --> 00:06:27,996
mode.


184
00:06:29,936 --> 00:06:32,386
Specialize if mono is legacy


185
00:06:32,386 --> 00:06:33,056
behavior.


186
00:06:33,246 --> 00:06:35,416
This is the same as bypass for


187
00:06:35,416 --> 00:06:37,546
any multichannel stream, which


188
00:06:37,546 --> 00:06:39,596
means a pass-through or down mix


189
00:06:39,596 --> 00:06:40,806
to the output format.


190
00:06:41,906 --> 00:06:44,016
With point source, the audio is


191
00:06:44,016 --> 00:06:45,826
sum-to-mono and rendered at the


192
00:06:45,826 --> 00:06:47,366
location of the player node.


193
00:06:47,646 --> 00:06:50,096
And with ambiance bed, the audio


194
00:06:50,096 --> 00:06:52,246
is anchored to the 3D world and


195
00:06:52,246 --> 00:06:53,596
is rotatable with the player


196
00:06:53,596 --> 00:06:55,456
node's position relative to the


197
00:06:55,456 --> 00:06:55,976
listener orientation.


198
00:06:59,326 --> 00:07:00,856
Here we see an example of


199
00:07:00,856 --> 00:07:02,616
ambience bed source mode with


200
00:07:02,616 --> 00:07:04,376
automatic rendering algorithm.


201
00:07:05,476 --> 00:07:07,506
After setting the properties, it


202
00:07:07,506 --> 00:07:09,156
is important to make sure the


203
00:07:09,156 --> 00:07:10,666
format that is used for the


204
00:07:10,666 --> 00:07:12,446
connection between player node


205
00:07:12,606 --> 00:07:14,596
and environment node contains


206
00:07:14,596 --> 00:07:15,936
the multichannel layout.


207
00:07:19,176 --> 00:07:21,546
Now let's talk about what's new


208
00:07:21,546 --> 00:07:22,606
in AVAudioSession.


209
00:07:25,316 --> 00:07:27,906
AVAudioSession prompt style is a


210
00:07:27,906 --> 00:07:30,576
hint to apps that play voice


211
00:07:30,616 --> 00:07:32,366
prompts in order to modify the


212
00:07:32,366 --> 00:07:34,076
style of the plate prompt.


213
00:07:35,036 --> 00:07:37,596
For example, if Siri is speaking


214
00:07:37,596 --> 00:07:39,116
or a phone call is ongoing,


215
00:07:39,506 --> 00:07:41,116
verbal navigation prompts is a


216
00:07:41,116 --> 00:07:42,756
confusing user experience.


217
00:07:43,696 --> 00:07:45,366
We also don't want Siri to


218
00:07:45,366 --> 00:07:47,046
record the navigation prompt.


219
00:07:47,946 --> 00:07:49,666
Navigation apps for example are


220
00:07:49,666 --> 00:07:51,326
encouraged to pay attention to


221
00:07:51,326 --> 00:07:53,536
prompt style changes and modify


222
00:07:53,536 --> 00:07:54,826
their prompts for better user


223
00:07:54,826 --> 00:07:55,566
experience.


224
00:07:56,276 --> 00:07:57,746
We have three prompt styles:


225
00:07:57,916 --> 00:08:00,066
none, short and normal.


226
00:08:00,756 --> 00:08:02,676
We can now indicate to disable


227
00:08:02,676 --> 00:08:04,446
prompts completely, play


228
00:08:04,446 --> 00:08:06,496
shortened prompts or play the


229
00:08:06,496 --> 00:08:07,446
regular prompts.


230
00:08:10,026 --> 00:08:11,126
Let's look at other


231
00:08:11,126 --> 00:08:12,946
AVAudioSession enhancements.


232
00:08:13,646 --> 00:08:15,766
The default policy is to mute


233
00:08:15,766 --> 00:08:17,406
haptics and system sounds when


234
00:08:17,406 --> 00:08:18,936
audio recording is active.


235
00:08:19,836 --> 00:08:21,926
A new property allow haptics and


236
00:08:21,926 --> 00:08:23,676
system sounds during recording,


237
00:08:24,106 --> 00:08:26,446
allows system sounds and haptics


238
00:08:26,446 --> 00:08:27,816
to play while the session is


239
00:08:27,816 --> 00:08:29,566
actively using an audio input.


240
00:08:30,366 --> 00:08:32,606
It can be said using the set


241
00:08:32,606 --> 00:08:34,035
allowHapticsAndSystem


242
00:08:34,035 --> 00:08:35,376
SoundsDuringRecording.


243
00:08:37,976 --> 00:08:40,096
For more information, please


244
00:08:40,096 --> 00:08:41,846
visit the developer website.


245
00:08:45,536 --> 00:08:47,266
Thank you for your attention.

